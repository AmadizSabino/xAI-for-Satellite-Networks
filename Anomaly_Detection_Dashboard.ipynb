{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHLbRT8yINhgZBLbsfhCz2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmadizSabino/xAI-for-Satellite-Networks/blob/main/Anomaly_Detection_Dashboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# Step 1 - Environment setup (Colab)\n",
        "# =======================================================\n",
        "!pip install --quiet --upgrade pip\n",
        "!pip install --quiet streamlit plotly pandas numpy pyngrok\n",
        "# Install libraries\n",
        "!pip install --upgrade pip\n",
        "!pip install streamlit plotly pandas pyngrok\n",
        "\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses\"\n",
        "DASHBOARD_DIR = os.path.join(BASE_DIR, \"dashboard\")\n",
        "os.makedirs(DASHBOARD_DIR, exist_ok=True)\n",
        "DASHBOARD_DIR, os.listdir(BASE_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H5v1TN2A9-P",
        "outputId": "18079fb0-f8df-4467-f8b0-5a95a34c1d21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard',\n",
              " ['Anomaly_Detection_Dashboard.ipynb',\n",
              "  'CIEL2_ManeuverEvents_R1.csv',\n",
              "  'ThrusterTemperaturePIDs.csv',\n",
              "  'AttitudePIDs.csv',\n",
              "  'LabelManeuverEvents.m',\n",
              "  'Archive',\n",
              "  'phase3_ESA-Mission1',\n",
              "  'SESGroundData_Oct-Nov_AS1.xlsx',\n",
              "  'artifacts_signal_loss',\n",
              "  'artifacts_sla',\n",
              "  'artifacts_handover',\n",
              "  'artifacts_powerfault',\n",
              "  'space_weather_gfz_kp_ap_2023_v1.csv',\n",
              "  'gfz_kp_ap_2023.csv',\n",
              "  'ses_comm_features.csv',\n",
              "  'ses_clean_10s.parquet',\n",
              "  'ses_comm_anomalies.csv',\n",
              "  'artifacts_jamming',\n",
              "  ' 3_3_SES_Prototype_BeamHandover.ipynb',\n",
              "  'ses_maneuver_features.csv',\n",
              "  'gfz_kp_ap_2012-01-01_2020-02-27.csv',\n",
              "  'ses_spaceweather_dataset.csv',\n",
              "  'artifacts_spaceweather',\n",
              "  'dashboard',\n",
              "  '3_3_SES_Prototype_SignalLoss.ipynb',\n",
              "  '3_3_SES_Jamming_Interference.ipynb',\n",
              "  '3_3_SES_Space_Weather.ipynb',\n",
              "  '3_3_SES_Prototype_SLA_Proxy.ipynb',\n",
              "  'artifacts_capacity',\n",
              "  '3_3_SES_Risk_Aware_Capacity_Advisor.ipynb',\n",
              "  'artifacts_stress',\n",
              "  '3_3_SES_Prototype_StressIndex.ipynb',\n",
              "  'OLD_Anomaly_Detection_Dashboard.ipynb'])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"$DASHBOARD_DIR\"\n",
        "\n",
        "!ls \"$BASE_DIR\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv9PAKsLBeOK",
        "outputId": "d7f17249-2a38-4255-ff24-a17a6a3fc630"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\tOLD_1_app.py  OLD_3app.py  OLD_5app.py\tOLD_7app.py\n",
            "assets\tOLD_2app.py   OLD_4app.py  OLD_6app.py\n",
            " 3_3_SES_Jamming_Interference.ipynb\n",
            "' 3_3_SES_Prototype_BeamHandover.ipynb'\n",
            " 3_3_SES_Prototype_SignalLoss.ipynb\n",
            " 3_3_SES_Prototype_SLA_Proxy.ipynb\n",
            " 3_3_SES_Prototype_StressIndex.ipynb\n",
            " 3_3_SES_Risk_Aware_Capacity_Advisor.ipynb\n",
            " 3_3_SES_Space_Weather.ipynb\n",
            " Anomaly_Detection_Dashboard.ipynb\n",
            " Archive\n",
            " artifacts_capacity\n",
            " artifacts_handover\n",
            " artifacts_jamming\n",
            " artifacts_powerfault\n",
            " artifacts_signal_loss\n",
            " artifacts_sla\n",
            " artifacts_spaceweather\n",
            " artifacts_stress\n",
            " AttitudePIDs.csv\n",
            " CIEL2_ManeuverEvents_R1.csv\n",
            " dashboard\n",
            " gfz_kp_ap_2012-01-01_2020-02-27.csv\n",
            " gfz_kp_ap_2023.csv\n",
            " LabelManeuverEvents.m\n",
            " OLD_Anomaly_Detection_Dashboard.ipynb\n",
            " phase3_ESA-Mission1\n",
            " ses_clean_10s.parquet\n",
            " ses_comm_anomalies.csv\n",
            " ses_comm_features.csv\n",
            " SESGroundData_Oct-Nov_AS1.xlsx\n",
            " ses_maneuver_features.csv\n",
            " ses_spaceweather_dataset.csv\n",
            " space_weather_gfz_kp_ap_2023_v1.csv\n",
            " ThrusterTemperaturePIDs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova secção"
      ],
      "metadata": {
        "id": "xMbqovEMCGbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# Step 2 - create app.py file\n",
        "# =======================================================\n",
        "\n",
        "import textwrap\n",
        "import os\n",
        "\n",
        "# Define BASE_DIR and DASHBOARD_DIR within this cell for independence\n",
        "BASE_DIR = \"/content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses\"\n",
        "DASHBOARD_DIR = os.path.join(BASE_DIR, \"dashboard\")\n",
        "\n",
        "app_code_raw = '''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "\n",
        "# ------------------------------\n",
        "# Paths and helpers\n",
        "# ------------------------------\n",
        "\n",
        "BASE_DIR = Path(__file__).resolve().parent.parent\n",
        "\n",
        "def load_csv(relative_paths, parse_dates=None):\n",
        "    paths = relative_paths if isinstance(relative_paths, (list, tuple)) else [relative_paths]\n",
        "    for rel in paths:\n",
        "        p = BASE_DIR / rel\n",
        "        if p.exists():\n",
        "            try:\n",
        "                return pd.read_csv(p, parse_dates=parse_dates)\n",
        "            except Exception:\n",
        "                return None\n",
        "    return None\n",
        "\n",
        "def load_image_path(relative_paths):\n",
        "    paths = relative_paths if isinstance(relative_paths, (list, tuple)) else [relative_paths]\n",
        "    for rel in paths:\n",
        "        p = BASE_DIR / rel\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "    return None\n",
        "\n",
        "# ------------------------------\n",
        "# Page wide layout\n",
        "# ------------------------------\n",
        "\n",
        "st.set_page_config(page_title=\"Satellite Anomaly Dashboard\",\n",
        "                   layout=\"wide\")\n",
        "\n",
        "# Sidebar navigation\n",
        "st.sidebar.title(\"Anomaly Dashboard\")\n",
        "view = st.sidebar.radio(\n",
        "    \"Select a view\",\n",
        "    [\n",
        "        \"Overview\",\n",
        "        \"Signal Loss\",\n",
        "        \"Jamming / Interference\",\n",
        "        \"SLA Breach\",\n",
        "        \"Beam Handover\",\n",
        "        \"Space Weather\",\n",
        "        \"Risk-aware Capacity Advisor\",\n",
        "        \"Stress Index & Joint Risk Radar\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Demo filters (top of sidebar)\n",
        "with st.sidebar.expander(\"Demo filters\", expanded=True):\n",
        "    st.caption(\"In a live system these would filter the underlying data.\")\n",
        "satellite = st.sidebar.selectbox(\"Satellite (aggregated data)\", [\"M003\", \"M008\", \"M015\", \"M017\", \"ALL\"])\n",
        "time_window = st.sidebar.selectbox(\"Time window\", [\"Last 24h\", \"Last 7 days\", \"Full dataset\"])\n",
        "\n",
        "# ------------------------------\n",
        "# Alert card helper\n",
        "# ------------------------------\n",
        "\n",
        "def render_alerts(df, id_col, time_col, severity_col, title, usecase_key, max_rows=3):\n",
        "    \"\"\"\n",
        "    Render a compact list of alert cards from a dataframe with id, time and severity columns.\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        # Small demo fallback set if nothing is available.\n",
        "        demo = pd.DataFrame(\n",
        "            {\n",
        "                id_col: [f\"ALERT-{i+1}\" for i in range(3)],\n",
        "                time_col: pd.date_range(\"2021-11-01\", periods=3, freq=\"H\"),\n",
        "                severity_col: [\"high\", \"medium\", \"medium\"],\n",
        "            }\n",
        "        )\n",
        "        df_to_show = demo\n",
        "    else:\n",
        "        df_to_show = df.sort_values(time_col, ascending=False).head(max_rows)\n",
        "\n",
        "    st.caption(title)\n",
        "\n",
        "    # IMPORTANT: this loop defines `row`, so everything below can use it\n",
        "    for i, (_, row) in enumerate(df_to_show.iterrows()):\n",
        "        with st.container():\n",
        "            markdown_content = f\"\"\"**{row[id_col]}**\n",
        "Time: {row[time_col]}\n",
        "Severity: {row[severity_col]}\"\"\"\n",
        "            st.markdown(markdown_content)\n",
        "\n",
        "            col_a, col_b = st.columns([1, 2])\n",
        "            with col_a:\n",
        "                st.button(\"Acknowledge\", key=f\"{usecase_key}_ack_{i}\")\n",
        "            with col_b:\n",
        "                st.caption(\n",
        "                    \"Typical action: open NOC ticket, attach evidence, notify on-call engineer.\"\n",
        "                )\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Overview page\n",
        "# ------------------------------\n",
        "\n",
        "def page_overview():\n",
        "    col_left, col_right = st.columns([2, 1])\n",
        "\n",
        "    with col_left:\n",
        "        st.title(\"Explainable AI for Satellite Networks Anomaly Detection\")\n",
        "        st.markdown(\n",
        "          \"\"\"\n",
        "            Monitoring based on ground telemetry, space weather and SLA metrics.\n",
        "            The goal is to give the Network Operations Center early insight into\n",
        "            issues that affect availability and customer experience.\n",
        "          \"\"\"\n",
        "        )\n",
        "\n",
        "        st.divider()\n",
        "\n",
        "        st.subheader(\"What this prototype does\")\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "- Tracks a set of anomaly use cases: signal loss, jamming or interference, SLA breach, beam handover issues,\n",
        "  space weather risk for maneuvers, capacity pressure and a combined stress index.\n",
        "- Uses historical SES data to learn what healthy behaviour looks like, then scores new windows for risk.\n",
        "- Uses explainable AI (mainly SHAP heatmaps) so operators can see **why** a window is flagged.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        st.divider()\n",
        "        st.subheader(\"High level anomaly detection performance (test windows)\")\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "**How to read these metrics**\n",
        "\n",
        "- **PR-AUC** (Precision–Recall area): how well the model lifts true anomalies above noise.\n",
        "  This is the main metric for rare events such as signal loss or SLA breach.\n",
        "\n",
        "- **ROC-AUC**: overall ability to separate normal vs. anomalous behaviour across all thresholds.\n",
        "  This can look optimistic when anomalies are very rare.\n",
        "\n",
        "- **Event precision / recall**:\n",
        "  Precision answers *“of the alerts raised, how many were real?”*;\n",
        "  Recall answers *“of all real events, how many did we catch?”*.\n",
        "\n",
        "In this prototype the models are tuned towards **high precision** so that operators can trust an alert,\n",
        "even if that means some events are missed (moderate recall) to avoid flooding the NOC with false positives.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        metrics = [\n",
        "            (\"Signal Loss model\",        0.72, 0.83, 0.93, 0.13),\n",
        "            (\"SLA early warning\",       0.25, 0.86, 1.00, 0.03),\n",
        "            (\"Beam Handover anomalies\", 0.022, 0.71, 0.50, 0.012),\n",
        "        ]\n",
        "\n",
        "        interpretations = {\n",
        "            \"Signal Loss model\": (\n",
        "                \"Strong at prioritising true signal-loss events over noise. \"\n",
        "                \"Most alerts are real (high precision), but it currently catches only a subset of all events \"\n",
        "                \"(moderate recall). Designed as a conservative early-warning signal.\"\n",
        "            ),\n",
        "            \"SLA early warning\": (\n",
        "                \"Identifies some windows at risk of SLA degradation. Alerts are very rare but almost always correct \"\n",
        "                \"(precision close to 1.0), so it behaves as a highly conservative early-warning indicator rather than \"\n",
        "                \"a complete SLA monitor.\"\n",
        "            ),\n",
        "            \"Beam Handover anomalies\": (\n",
        "                \"Weaker performance, which is expected given the extreme rarity and complexity of handover issues. \"\n",
        "                \"Surfaces some interesting cases but still misses many true problems and generates some false alerts. \"\n",
        "                \"Marked as *prototype / for further tuning*.\"\n",
        "            ),\n",
        "        }\n",
        "\n",
        "        m_cols = st.columns(len(metrics))\n",
        "        for col, (name, pr, roc, p, r) in zip(m_cols, metrics):\n",
        "            with col:\n",
        "                st.markdown(f\"**{name}**\")\n",
        "                st.metric(\"PR-AUC\", f\"{pr:.3f}\")\n",
        "                st.metric(\"ROC-AUC\", f\"{roc:.3f}\")\n",
        "                st.caption(f\"Event precision / recall: **{p:.2f} / {r:.2f}**\")\n",
        "                with st.expander(\"Plain-English summary\", expanded=False):\n",
        "                    st.write(interpretations[name])\n",
        "\n",
        "        st.divider()\n",
        "        st.subheader(\"Operational notes (prototype)\")\n",
        "\n",
        "        op_col1, op_col2 = st.columns([2, 1])\n",
        "        with op_col1:\n",
        "            st.markdown(\n",
        "              \"\"\"\n",
        "                In a production live environment this dashboard would be connected to the NOC data lake\n",
        "                and refreshed continuously. Operator feedback on alerts would be stored for model retraining\n",
        "                and for tracking false positives.\n",
        "              \"\"\"\n",
        "            )\n",
        "            _ = st.text_area(\n",
        "                \"Operator feedback (demo only, not persisted)\",\n",
        "                placeholder=\"Example: Signal loss alert at 05:50 UTC was a false alarm – modem under maintenance.\",\n",
        "            )\n",
        "        with op_col2:\n",
        "            st.markdown(\"**Data freshness**\")\n",
        "            st.markdown(\"- Ground telemetry window: **Oct–Nov 2021**\")\n",
        "            st.markdown(\"- Space weather window: **2012–2020**\")\n",
        "            st.markdown(\"- Last model run (prototype): **2025-11-25 UTC**\")\n",
        "\n",
        "    with col_right:\n",
        "        gif_url = \"https://i.gifer.com/AHJv.gif\"\n",
        "        st.image(gif_url, caption=\"Orbital view (demo)\", use_container_width=True)\n",
        "\n",
        "# ------------------------------\n",
        "# Signal Loss page\n",
        "# ------------------------------\n",
        "\n",
        "def page_signal_loss():\n",
        "    st.title(\"Signal Loss – modem level detection\")\n",
        "\n",
        "    st.markdown(\"### What this use case monitors\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        The model watches a small set of modem power and quality indicators over time.\n",
        "        When they drift away from their usual pattern, the window is flagged as a potential signal loss scenario.\n",
        "        It focuses on bursts and ramps in input and output power rather than single out-of-range samples.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Why this matters for operators\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        - Impacts service availability and can trigger SLA penalties.\n",
        "        - Distinguishing true RF issues from planned maintenance is difficult at scale.\n",
        "        - Manual triage across many modems and beams is time-consuming; automation helps focus operator attention.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### How this prototype works\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        - Features are built from modem IN and OUT power statistics over short windows (mean, min, max, slopes).\n",
        "        - An autoencoder-style model learns the typical pattern and assigns an anomaly score to each window.\n",
        "        - A threshold and eventisation logic convert noisy scores into a small number of operational alerts.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    col_main, col_side = st.columns([2, 1])\n",
        "\n",
        "    with col_main:\n",
        "        st.markdown(\"### SHAP heatmaps – drivers of signal loss\")\n",
        "\n",
        "        event_img = load_image_path(\"artifacts_signal_loss/signal_loss_event_heatmap.png\")\n",
        "        cont_img = load_image_path(\"artifacts_signal_loss/signal_loss_continuous_heatmap.png\")\n",
        "\n",
        "        if event_img:\n",
        "            st.image(event_img, caption=\"Signal Loss – SHAP heatmap around one event\", use_container_width=True)\n",
        "        if cont_img:\n",
        "            st.image(cont_img, caption=\"Signal Loss – continuous SHAP importance over time\", use_container_width=True)\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "The heatmaps show **which modem statistics pushed the model towards signal loss**.\n",
        "\n",
        "- **Rows**: modem-level features (IN/OUT power statistics, possibly per-channel aggregates).\n",
        "- **Columns**: time steps within the analysed window.\n",
        "- **Warm colours (red/orange)**: features that *increase* the anomaly score in that window.\n",
        "- **Cool colours (blue)**: features that *reduce* it or confirm normal behaviour.\n",
        "\n",
        "Operators can quickly see whether a suspected event is driven by a single modem, many modems together, or noisy data.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        st.markdown(\"### Example trend\")\n",
        "\n",
        "        scores = load_csv(\"artifacts_signal_loss/test_scores_raw.csv\", parse_dates=[\"timestamp\"])\n",
        "\n",
        "        if scores is not None:\n",
        "            if \"timestamp\" in scores.columns:\n",
        "                scores = scores.rename(columns={\"timestamp\": \"time\"})\n",
        "            if \"proba_raw\" in scores.columns:\n",
        "                scores = scores.rename(columns={\"proba_raw\": \"anomaly_score\"})\n",
        "\n",
        "            if \"time\" in scores.columns and \"anomaly_score\" in scores.columns:\n",
        "                scores = scores.sort_values(\"time\").tail(1000)\n",
        "                fig = px.line(\n",
        "                    scores,\n",
        "                    x=\"time\",\n",
        "                    y=\"anomaly_score\",\n",
        "                    title=\"Recent signal-loss anomaly scores\",\n",
        "                )\n",
        "                fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "            else:\n",
        "                st.caption(\"Signal-loss scores CSV found, but expected columns are missing; trend chart skipped.\")\n",
        "        else:\n",
        "            st.caption(\"Signal-loss scores CSV not found; trend chart skipped in this environment.\")\n",
        "\n",
        "    with col_side:\n",
        "        gif_url = \"https://i.gifer.com/K6mM.gif\"\n",
        "        st.image(gif_url, caption=\"Signal Loss illustration (demo)\", use_container_width=True)\n",
        "\n",
        "        st.markdown(\"### Alerts and suggested actions\")\n",
        "\n",
        "        events = load_csv(\n",
        "            [\"artifacts_signal_loss/test_eventized_scores.csv\", \"artifacts_signal_loss/test_scores.csv\"],\n",
        "            parse_dates=[\"t_start\", \"t_end\"],\n",
        "        )\n",
        "        if events is not None:\n",
        "            events[\"time_center\"] = events[\"t_start\"]\n",
        "            events[\"severity\"] = np.where(events.get(\"label\", 1) == 1, \"high\", \"medium\")\n",
        "            events[\"id\"] = events.get(\"modem\", \"Unknown modem\")\n",
        "            alerts_df = events[[\"id\", \"time_center\", \"severity\"]]\n",
        "        else:\n",
        "            alerts_df = None\n",
        "\n",
        "        render_alerts(alerts_df, \"id\", \"time_center\", \"severity\", \"Recent high-risk windows\", \"signal_loss\")\n",
        "\n",
        "        st.markdown(\n",
        "          \"\"\"\n",
        "            - Correlate with weather, maintenance and pointing information.\n",
        "            - If multiple modems on the same beam are affected, escalate as potential RF impairment.\n",
        "            - If a single modem only, open a customer ticket and investigate the terminal side first.\n",
        "          \"\"\"\n",
        "        )\n",
        "\n",
        "# ------------------------------\n",
        "# Jamming / interference page\n",
        "# ------------------------------\n",
        "\n",
        "def page_jamming():\n",
        "    st.title(\"Jamming / Interference – spectrum-level anomalies\")\n",
        "\n",
        "    st.markdown(\"### What this use case monitors\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        The jamming detector looks for unusual energy patterns in a subset of modem outputs.\n",
        "        Instead of analysing full spectra, it uses modem statistics as a proxy for interference on the uplink or downlink.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Why this matters for operators\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        - Intentional or accidental jamming can degrade whole beams and affect many customers at once.\n",
        "        - Early detection enables geolocation, mitigation and reconfiguration before the impact widens.\n",
        "        - Weak or intermittent interferers can remain unnoticed for hours without automated monitoring.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### How this prototype works\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        - An unsupervised model learns the joint behaviour of modem statistics during quiet periods.\n",
        "        - Windows where many channels move together in an unusual way receive a high anomaly score.\n",
        "        - SHAP explanations highlight which channels and time slices drove each alarm.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    col_main, col_side = st.columns([2, 1])\n",
        "\n",
        "    with col_main:\n",
        "        st.markdown(\"### SHAP heatmaps – interference patterns\")\n",
        "\n",
        "        event_img = load_image_path(\"artifacts_jamming/jamming_event_heatmap.png\")\n",
        "        cont_img = load_image_path(\"artifacts_jamming/jamming_continuous_heatmap.png\")\n",
        "\n",
        "        if event_img:\n",
        "            st.image(\n",
        "                event_img,\n",
        "                caption=\"Jamming – SHAP heatmap around a suspected interference event\",\n",
        "                use_container_width=True,\n",
        "            )\n",
        "        if cont_img:\n",
        "            st.image(\n",
        "                cont_img,\n",
        "                caption=\"Jamming – continuous SHAP importance over time\",\n",
        "                use_container_width=True,\n",
        "            )\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "These SHAP heatmaps show **which modem statistics contributed most to the model's decision** that a time\n",
        "window is suspicious for interference.\n",
        "\n",
        "**Axes and colours**\n",
        "\n",
        "- **Rows**: modem- or channel-level statistics (e.g. power, quality, error counters) aggregated over short windows.\n",
        "- **Columns**: time steps within the analysed window.\n",
        "- **Warm colours (red/orange)**: features that *increase* the jamming anomaly score.\n",
        "- **Cool colours (blue)**: features that *reduce* the score or confirm normal behaviour.\n",
        "\n",
        "**Typical jamming signatures**\n",
        "\n",
        "- **Wide horizontal bands across several rows at the same time**\n",
        "  → Many channels show abnormal behaviour together → suggestive of **wideband interference** or a jammer affecting\n",
        "  a whole beam or polarisation.\n",
        "\n",
        "- **Strong activity concentrated in a small number of rows**\n",
        "  → Only a few channels or carriers are affected → more indicative of **localised carrier problems** or\n",
        "  customer-specific issues.\n",
        "\n",
        "- **Short, intense vertical stripes**\n",
        "  → Sudden bursts of abnormal energy → could indicate **short-lived or bursty interferers**.\n",
        "\n",
        "**Operational use**\n",
        "\n",
        "- Confirm whether an alert is driven by a **single noisy modem** or a **coherent pattern across many channels**.\n",
        "- Prioritise events with **multi-row, multi-time anomalies** as stronger candidates for real jamming.\n",
        "- Use the SHAP rows to decide which beams/channels to inspect first in external spectrum monitoring tools.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with col_side:\n",
        "        st.markdown(\"### Alerts and suggested actions\")\n",
        "\n",
        "        events = load_csv(\"artifacts_jamming/test_eventized_scores.csv\", parse_dates=[\"t_start\", \"t_end\"])\n",
        "        if events is not None:\n",
        "            events[\"time_center\"] = events[\"t_start\"]\n",
        "            events[\"severity\"] = np.where(events.get(\"label\", 1) == 1, \"high\", \"medium\")\n",
        "            events[\"id\"] = events.get(\"beam\", \"Unknown beam\")\n",
        "            alerts_df = events[[\"id\", \"time_center\", \"severity\"]]\n",
        "        else:\n",
        "            alerts_df = None\n",
        "\n",
        "        render_alerts(alerts_df, \"id\", \"time_center\", \"severity\", \"Recent high-risk windows\", \"jamming\")\n",
        "\n",
        "        st.markdown(\n",
        "          \"\"\"\n",
        "            - Cross-check with spectrum monitoring tools and confirm on a waterfall view.\n",
        "            - Start geolocation if multiple beams show correlated interference.\n",
        "            - Coordinate with customers to move critical carriers if necessary.\n",
        "          \"\"\"\n",
        "        )\n",
        "\n",
        "# ------------------------------\n",
        "# SLA Breach page\n",
        "# ------------------------------\n",
        "\n",
        "def page_sla():\n",
        "    st.title(\"SLA Breach – throughput early warning\")\n",
        "\n",
        "    st.markdown(\"### What this use case monitors\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        This model watches a throughput proxy KPI and compares it against SLA thresholds learned from historical data.\n",
        "        Instead of only reacting once a customer complains, it aims to provide a few minutes of warning that traffic\n",
        "        is likely to fall below an agreed level.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Why this matters for operators\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        - SLA violations impact revenue and customer satisfaction.\n",
        "        - Without early warning, the NOC is often reactive rather than proactive.\n",
        "        - Even a small lead time is valuable to reroute traffic or add capacity.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    col_main, col_side = st.columns([2, 1])\n",
        "\n",
        "    with col_main:\n",
        "        st.markdown(\"### SLA thresholds and breaches (example windows)\")\n",
        "\n",
        "        sla_df = load_csv(\"artifacts_sla/sla_breach_events.csv\", parse_dates=[\"start\", \"end\"])\n",
        "        if sla_df is not None:\n",
        "            fig = px.scatter(\n",
        "                sla_df.sort_values(\"start\").head(200),\n",
        "                x=\"start\",\n",
        "                y=\"duration_s\",\n",
        "                color=\"severity\" if \"severity\" in sla_df.columns else None,\n",
        "                title=\"Example windows leading into SLA breaches\",\n",
        "            )\n",
        "            fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "        else:\n",
        "            st.info(\"No SLA breach CSV found in artifacts_sla/. Showing explanations only.\")\n",
        "\n",
        "        st.markdown(\"### SHAP heatmaps – drivers of SLA risk\")\n",
        "\n",
        "        event_img = load_image_path(\"artifacts_sla/sla_event_heatmap.png\")\n",
        "        cont_img = load_image_path(\"artifacts_sla/sla_continuous_heatmap.png\")\n",
        "\n",
        "        if event_img:\n",
        "            st.image(\n",
        "                event_img,\n",
        "                caption=\"SLA – SHAP heatmap around one breach\",\n",
        "                use_container_width=True,\n",
        "            )\n",
        "        if cont_img:\n",
        "            st.image(\n",
        "                cont_img,\n",
        "                caption=\"SLA – continuous SHAP importance over time\",\n",
        "                use_container_width=True,\n",
        "            )\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "The SLA SHAP heatmaps explain **which KPIs pushed the model towards predicting an SLA breach** in each time window.\n",
        "\n",
        "**Axes and colours**\n",
        "\n",
        "- **Rows**: engineered features such as current throughput level, recent minimum throughput, volatility, slope and\n",
        "  short-term history of the KPI.\n",
        "- **Columns**: time steps leading up to and after a potential SLA issue.\n",
        "- **Warm colours (red/orange)**: values that *increase* the probability of an SLA breach.\n",
        "- **Cool colours (blue)**: values that *decrease* the probability and support a “healthy” interpretation.\n",
        "\n",
        "**Typical SLA risk signatures**\n",
        "\n",
        "- **Deep blue patches on throughput rows just before a breach**\n",
        "  → Throughput is consistently below the model’s expectation for a healthy window → strong breach evidence.\n",
        "\n",
        "- **Red spikes on slope or volatility features**\n",
        "  → Sharp drops or unstable throughput over a short period → treated as early-warning symptoms.\n",
        "\n",
        "- **Sustained warm colours across several throughput-related rows**\n",
        "  → Combination of low level, high volatility and negative trend → degraded and unstable service.\n",
        "\n",
        "**Operational use**\n",
        "\n",
        "- Separate **hard SLA breaches** from **borderline unstable windows** that may soon degrade.\n",
        "- Understand whether a predicted risk is driven mainly by **absolute level** or by **instability and sharp drops**.\n",
        "- Justify proactive actions (capacity boost, rerouting, customer communication) before a formal breach occurs.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with col_side:\n",
        "        st.markdown(\"### Alerts and suggested actions\")\n",
        "\n",
        "        sla_df = load_csv(\"artifacts_sla/sla_breach_events.csv\", parse_dates=[\"start\", \"end\"])\n",
        "        if sla_df is not None:\n",
        "            sla_df = sla_df.copy()\n",
        "            sla_df[\"time_center\"] = sla_df[\"start\"]\n",
        "            sla_df[\"severity\"] = np.where(sla_df.get(\"breach_flag\", 1) == 1, \"high\", \"medium\")\n",
        "            sla_df[\"id\"] = sla_df.get(\"kpi_id\", \"SLA throughput\")\n",
        "            alerts_df = sla_df[[\"id\", \"time_center\", \"severity\"]]\n",
        "        else:\n",
        "            alerts_df = None\n",
        "\n",
        "        render_alerts(alerts_df, \"id\", \"time_center\", \"severity\", \"Current SLA risk windows\", \"sla\")\n",
        "\n",
        "        st.markdown(\n",
        "          \"\"\"\n",
        "            - If predicted breach is local to one beam, check utilisation and consider temporary capacity boost.\n",
        "            - If several beams show risk, escalate to network planning and investigate ground segment issues.\n",
        "          \"\"\"\n",
        "        )\n",
        "\n",
        "# ------------------------------\n",
        "# Beam Handover page\n",
        "# ------------------------------\n",
        "\n",
        "def page_handover():\n",
        "    st.title(\"Beam Handover – quality after beam changes\")\n",
        "\n",
        "    st.markdown(\"### What this use case monitors\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        Whenever the satellite or network controller moves a terminal from one beam to another,\n",
        "        there is a short period where throughput can dip. This model tracks handovers and highlights those\n",
        "        where throughput drops more than expected or recovers slowly.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Why this matters for operators\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        - Poorly behaving handovers can create repeated short outages that are hard to diagnose.\n",
        "        - They often affect mobile or aeronautical customers, which are especially sensitive to quality.\n",
        "        - Early visibility enables targeted tuning of handover parameters.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    col_main, col_side = st.columns([2, 1])\n",
        "\n",
        "    with col_main:\n",
        "        st.markdown(\"### SHAP heatmaps – quality around handovers\")\n",
        "\n",
        "        event_img = load_image_path(\"artifacts_handover/handover_event_heatmap.png\")\n",
        "        cont_img = load_image_path(\"artifacts_handover/handover_continuous_heatmap.png\")\n",
        "\n",
        "        if event_img:\n",
        "            st.image(\n",
        "                event_img,\n",
        "                caption=\"Beam Handover – SHAP heatmap around one anomalous handover\",\n",
        "                use_container_width=True,\n",
        "            )\n",
        "        if cont_img:\n",
        "            st.image(\n",
        "                cont_img,\n",
        "                caption=\"Beam Handover – continuous SHAP importance over time\",\n",
        "                use_container_width=True,\n",
        "            )\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "These heatmaps show how the model evaluates handover quality **before, during and after** the beam change.\n",
        "\n",
        "**Axes and structure**\n",
        "\n",
        "- **Rows**: features such as throughput before handover, throughput after handover, percentage drop, recovery time,\n",
        "  packet loss, and related quality indicators.\n",
        "- **Columns**: time windows ordered around the handover moment. A vertical reference separates **pre-handover**\n",
        "  and **post-handover** windows.\n",
        "- **Warm colours (red/orange)**: features that *increase* the anomaly score (concern about handover quality).\n",
        "- **Cool colours (blue)**: features that push the model towards normal behaviour.\n",
        "\n",
        "**Typical handover anomaly signatures**\n",
        "\n",
        "- **Warm regions immediately after the handover time**\n",
        "  → Post-handover windows where throughput is low or recovery is slow → the new beam is not delivering expected quality.\n",
        "\n",
        "- **Strong warm colours on “drop percentage” or “minimum throughput after handover” rows**\n",
        "  → Larger-than-expected drop from pre- to post-handover throughput → potential mis-tuned parameters, coverage edge\n",
        "  effects, or interference.\n",
        "\n",
        "- **Sustained warm colours across multiple post-handover windows**\n",
        "  → Prolonged poor performance rather than a brief transient → operationally critical and worth engineering follow-up.\n",
        "\n",
        "**Operational use**\n",
        "\n",
        "- Distinguish events where conditions were poor **before** the handover from those where the handover itself degraded quality.\n",
        "- Prioritise investigation on handovers where **recovery time and drop percentage stay red** over several windows.\n",
        "- Provide feedback on specific events where explanations do not match operator perception, feeding future retraining.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with col_side:\n",
        "        st.markdown(\"### Alerts and suggested actions\")\n",
        "\n",
        "        events = load_csv(\"artifacts_handover/handover_table.csv\", parse_dates=[\"t\"])\n",
        "        if events is not None:\n",
        "            events = events.tail(200)\n",
        "            events[\"time_center\"] = events[\"t\"]\n",
        "            events[\"severity\"] = np.where(events[\"drop_pct\"].abs() > 0.05, \"high\", \"medium\")\n",
        "            events[\"id\"] = events.get(\"beam_id\", \"Unknown beam\")\n",
        "            alerts_df = events[[\"id\", \"time_center\", \"severity\"]]\n",
        "        else:\n",
        "            alerts_df = None\n",
        "\n",
        "        render_alerts(alerts_df, \"id\", \"time_center\", \"severity\", \"Recent anomalous handovers\", \"handover\")\n",
        "\n",
        "        st.markdown(\n",
        "          \"\"\"\n",
        "            - Check whether the same customer or route is affected repeatedly.\n",
        "            - Inspect handover timing relative to satellite motion and beam footprints.\n",
        "            - Consider adjusting hysteresis or thresholds for problem beams.\n",
        "          \"\"\"\n",
        "        )\n",
        "\n",
        "# ------------------------------\n",
        "# Space Weather page\n",
        "# ------------------------------\n",
        "\n",
        "def page_space_weather():\n",
        "    st.title(\"Space Weather – maneuver risk\")\n",
        "\n",
        "    st.markdown(\"### What this use case monitors\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        Space weather indices such as Kp and ap capture geomagnetic activity.\n",
        "        This prototype links those indices with thruster temperature and attitude error during station-keeping and\n",
        "        unload maneuvers, to flag windows where maneuver risk may be elevated.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Why this matters for operators\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        - During strong geomagnetic storms the environment around the spacecraft changes and control margins shrink.\n",
        "        - Maneuvers executed in those periods may have higher fuel usage or tighter thermal constraints.\n",
        "        - A simple risk indicator helps flight dynamics teams choose safer windows.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    col_main, col_side = st.columns([2, 1])\n",
        "\n",
        "    with col_main:\n",
        "        st.markdown(\"### SHAP heatmaps – maneuver risk under space weather\")\n",
        "\n",
        "        event_img = load_image_path(\"artifacts_spaceweather/spaceweather_risky_heatmap.png\")\n",
        "        cont_img = load_image_path(\"artifacts_spaceweather/spaceweather_continuous_heatmap.png\")\n",
        "\n",
        "        if event_img:\n",
        "            st.image(\n",
        "                event_img,\n",
        "                caption=\"Space Weather – SHAP heatmap for top risky maneuvers\",\n",
        "                use_container_width=True,\n",
        "            )\n",
        "        if cont_img:\n",
        "            st.image(\n",
        "                cont_img,\n",
        "                caption=\"Space Weather – continuous SHAP importance over time\",\n",
        "                use_container_width=True,\n",
        "            )\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "These heatmaps explain **why the model considers certain maneuvers to be higher risk** from a space-weather\n",
        "perspective.\n",
        "\n",
        "**Axes and feature types**\n",
        "\n",
        "- **Rows** typically include:\n",
        "  - Thruster temperature statistics during the maneuver\n",
        "  - Attitude error metrics\n",
        "  - Space weather indices (Kp, ap) and storm flags\n",
        "  - Short-term history of geomagnetic activity before the maneuver\n",
        "- **Columns**: maneuvers or time windows considered by the model.\n",
        "- **Warm colours (red/orange)**: values that push the classifier towards the “risky” class.\n",
        "- **Cool colours (blue)**: values that support a nominal or low-risk classification.\n",
        "\n",
        "**Typical risky maneuver signatures**\n",
        "\n",
        "- **Warm blocks on thruster temperature and attitude error rows during a maneuver**\n",
        "  → Thrusters running hotter or control margins tighter than usual → closer to engineering limits.\n",
        "\n",
        "- **Sustained warm bands on Kp or storm-related features before and during maneuvers**\n",
        "  → Prolonged geomagnetic disturbance around the maneuver window → external conditions make control more challenging.\n",
        "\n",
        "- **Combined warm patterns across both spacecraft and space-weather rows**\n",
        "  → Internal telemetry and external indices both pointing towards increased risk → maneuvers where postponement\n",
        "  or extra monitoring may be most justified.\n",
        "\n",
        "**Operational use**\n",
        "\n",
        "- Distinguish maneuvers that are risky **due to internal telemetry only** from those that are risky **due to disturbed space weather**.\n",
        "- Better justify decisions to **delay non-urgent maneuvers** when geomagnetic activity is high.\n",
        "- Build intuition over time about which combinations of Kp, attitude error and thruster behaviour tend to precede\n",
        "  operational issues.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with col_side:\n",
        "        st.markdown(\"### Alerts and suggested actions\")\n",
        "\n",
        "        maneuvers = load_csv(\"ses_spaceweather_dataset.csv\", parse_dates=[\"time\"])\n",
        "        if maneuvers is not None and \"risk_score\" in maneuvers.columns:\n",
        "            maneuvers = maneuvers.sort_values(\"time\", ascending=False).head(20)\n",
        "            maneuvers[\"time_center\"] = maneuvers[\"time\"]\n",
        "            maneuvers[\"severity\"] = np.where(maneuvers[\"risk_score\"] > 0.6, \"high\", \"medium\")\n",
        "            maneuvers[\"id\"] = maneuvers[\"maneuver_type\"]\n",
        "            alerts_df = maneuvers[[\"id\", \"time_center\", \"severity\"]]\n",
        "        else:\n",
        "            alerts_df = None\n",
        "\n",
        "        render_alerts(alerts_df, \"id\", \"time_center\", \"severity\", \"Upcoming or recent risky maneuvers\", \"spaceweather\")\n",
        "\n",
        "        st.markdown(\n",
        "          \"\"\"\n",
        "            - Avoid planning non-urgent maneuvers during long periods with high Kp.\n",
        "            - Coordinate with ground segment teams when storm intensity is high, as link margins may also be affected.\n",
        "          \"\"\"\n",
        "        )\n",
        "\n",
        "# ------------------------------\n",
        "# Risk aware capacity advisor\n",
        "# ------------------------------\n",
        "\n",
        "def synth_capacity_demo():\n",
        "    \\\"\\\"\\\"Create synthetic capacity and demand for illustration if no CSV exists.\\\"\\\"\\\"\n",
        "    idx = pd.date_range(\"2021-10-25\", \"2021-11-01\", freq=\"H\")\n",
        "    beams = [\"Beam-A\", \"Beam-B\", \"Beam-C\"]\n",
        "    rows = []\n",
        "    rng = np.random.default_rng(42)\n",
        "    for b in beams:\n",
        "        base_cap = rng.uniform(200, 260)\n",
        "        for t in idx:\n",
        "            demand = base_cap * rng.uniform(0.4, 1.2)\n",
        "            cap = base_cap * rng.uniform(0.9, 1.1)\n",
        "            rows.append({\"time\": t, \"beam\": b, \"capacity\": cap, \"demand\": demand})\n",
        "    df = pd.DataFrame(rows)\n",
        "    df[\"headroom\"] = df[\"capacity\"] - df[\"demand\"]\n",
        "    df[\"risk_index\"] = 1.0 - (df[\"headroom\"] / df[\"capacity\"]).clip(0, 1)\n",
        "    return df\n",
        "\n",
        "def page_capacity():\n",
        "    st.title(\"Risk-aware capacity advisor (prototype)\")\n",
        "\n",
        "    st.markdown(\"### What this use case monitors\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        This page tracks how close traffic demand is to the available capacity on each beam or region.\n",
        "        When demand rises towards the capacity limit, the risk of congestion and throughput degradation increases.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### What this view shows\")\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "This view highlights beams or regions where **traffic demand is getting close to the available capacity**.\n",
        "\n",
        "**How to read the chart:**\n",
        "- **Capacity** is the estimated bandwidth the system can safely deliver.\n",
        "- **Demand** is how much bandwidth customers are actually trying to use.\n",
        "- **Risk index** reflects how tight the margin is between demand and capacity:\n",
        "  - Low risk → Plenty of room\n",
        "  - Medium risk → Demand increasing into the normal operating range\n",
        "  - High risk → Demand is close to or above the safe operating limit\n",
        "\n",
        "**Operational meaning:**\n",
        "- A rising risk index signals beams that may soon become overloaded.\n",
        "- Persistent high risk may require:\n",
        "  - Temporary capacity boosts\n",
        "  - Rerouting or reshaping traffic\n",
        "  - Escalation to planning/engineering teams\n",
        "\n",
        "This gives early visibility into congestion risks *before* customers feel an impact.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Why this matters for operators\")\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "When traffic demand rises close to the available capacity, **customer experience can degrade quickly**, even before\n",
        "traditional alarms or customer tickets appear.\n",
        "\n",
        "This view helps operators to:\n",
        "\n",
        "- Identify beams or regions that are **about to become congested**\n",
        "- Act before customers notice problems\n",
        "- Prioritise which beams require operational attention\n",
        "- Coordinate with planning or engineering teams when capacity is consistently tight\n",
        "- Consider mitigations such as temporary capacity boosts or rerouting traffic\n",
        "\n",
        "Early visibility allows the NOC to stay **proactive** rather than reactive.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    df = load_csv(\"artifacts_capacity/capacity_risk_demo.csv\", parse_dates=[\"time\"])\n",
        "    if df is None:\n",
        "        df = synth_capacity_demo()\n",
        "\n",
        "    beam_options = [\"ALL\"] + sorted(df[\"beam\"].unique().tolist())\n",
        "    beam = st.selectbox(\"Beam or region\", beam_options)\n",
        "    horizon_label = st.selectbox(\"Forecast horizon\", [\"Next 6 hours\", \"Next 24 hours\", \"Next 72 hours\"])\n",
        "    horizon_hours = 6 if \"6\" in horizon_label else (24 if \"24\" in horizon_label else 72)\n",
        "\n",
        "    latest_time = df[\"time\"].max()\n",
        "    window_start = latest_time - pd.Timedelta(hours=horizon_hours)\n",
        "    df_win = df[df[\"time\"].between(window_start, latest_time)].copy()\n",
        "    if beam != \"ALL\":\n",
        "        df_win = df_win[df_win[\"beam\"] == beam]\n",
        "\n",
        "    st.markdown(\"### Capacity, demand and risk over selected horizon\")\n",
        "    fig = px.line(\n",
        "        df_win,\n",
        "        x=\"time\",\n",
        "        y=[\"capacity\", \"demand\", \"risk_index\"],\n",
        "        labels={\"value\": \"Mbps / risk\", \"variable\": \"Series\"},\n",
        "    )\n",
        "    fig.update_layout(margin=dict(l=0, r=0, t=40, b=0), legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02))\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        Risk index values close to 1.0 indicate little spare headroom between demand and capacity.\n",
        "        In a production system this would be driven by a proper demand forecast and spectrum plan optimisation model.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Alerts and suggested actions\")\n",
        "    df_last = df_win.sort_values(\"time\", ascending=False).head(10)\n",
        "    df_last[\"severity\"] = np.where(df_last[\"risk_index\"] > 0.8, \"high\", \"medium\")\n",
        "    df_last[\"id\"] = df_last[\"beam\"]\n",
        "    df_last[\"time_center\"] = df_last[\"time\"]\n",
        "    alerts_df = df_last[[\"id\", \"time_center\", \"severity\"]]\n",
        "    render_alerts(alerts_df, \"id\", \"time_center\", \"severity\", \"Beams with highest short-term capacity risk\", \"capacity\")\n",
        "\n",
        "    st.markdown(\"#### Animated illustration placeholder\")\n",
        "    st.caption(\"Placeholder for an animation showing beams changing colour as capacity pressure increases.\")\n",
        "\n",
        "# ------------------------------\n",
        "# Stress index page\n",
        "# ------------------------------\n",
        "\n",
        "def synth_stress_demo():\n",
        "    \\\"\\\"\\\"Create synthetic stress index for illustration if no CSV exists.\\\"\\\"\\\"\n",
        "    idx = pd.date_range(\"2021-10-25\", \"2021-11-01\", freq=\"H\")\n",
        "    rng = np.random.default_rng(123)\n",
        "    df = pd.DataFrame({\"time\": idx})\n",
        "    df[\"signal_loss_risk\"] = rng.uniform(0, 0.6, len(idx))\n",
        "    df[\"jamming_risk\"] = rng.uniform(0, 0.5, len(idx))\n",
        "    df[\"sla_risk\"] = rng.uniform(0, 0.7, len(idx))\n",
        "    df[\"capacity_risk\"] = rng.uniform(0, 0.8, len(idx))\n",
        "    df[\"stress_index\"] = df[[\"signal_loss_risk\", \"jamming_risk\", \"sla_risk\", \"capacity_risk\"]].max(axis=1)\n",
        "    return df\n",
        "\n",
        "def page_stress():\n",
        "    st.title(\"Stress index and joint risk radar\")\n",
        "\n",
        "    st.markdown(\"### What this use case monitors\")\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        The stress index combines signals from several models into one compact view.\n",
        "        Instead of four or five separate alert streams, the NOC gets an at-a-glance indicator of how stressed the\n",
        "        network is over time on each satellite.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### What this view shows\")\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "The stress index gives a **single combined view** of several anomaly indicators:\n",
        "signal loss, jamming/interference, SLA degradation risk, and capacity pressure.\n",
        "\n",
        "**How to read the chart:**\n",
        "- The line moves up whenever **any** underlying model shows elevated risk.\n",
        "- Peaks indicate times when the network experienced:\n",
        "  - Unusual modem behaviour\n",
        "  - Interference events\n",
        "  - SLA-related throughput issues\n",
        "  - Capacity tightening\n",
        "\n",
        "This provides a fast, at-a-glance understanding of overall satellite network health.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Why this matters for operators\")\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "Operators normally need to monitor several different anomaly indicators separately\n",
        "(signal loss, interference, SLA risk, capacity pressure). The **stress index combines these signals**,\n",
        "helping operators instantly understand whether the network is behaving normally or under pressure.\n",
        "\n",
        "This view helps operators to:\n",
        "\n",
        "- Gauge **overall network health** at a glance\n",
        "- Detect **multi-beam or network-wide issues** quickly\n",
        "- Decide which use-case page requires immediate attention\n",
        "- Spot patterns that might be missed when looking at individual models\n",
        "- Prioritise responses during periods of operational stress\n",
        "\n",
        "A rising stress index is a clear signal that the NOC should investigate further.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    df = load_csv(\"artifacts_stress/stress_index_demo.csv\", parse_dates=[\"time\"])\n",
        "    if df is None:\n",
        "        df = synth_stress_demo()\n",
        "\n",
        "    st.markdown(\"### Stress index over time\")\n",
        "    fig = px.line(df, x=\"time\", y=\"stress_index\", title=\"Combined stress index\")\n",
        "    fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    st.markdown(\n",
        "      \"\"\"\n",
        "        Peaks in the stress index correspond to periods where at least one underlying model showed elevated risk.\n",
        "        In a production deployment this page would link back to the individual use case pages for root cause analysis.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Alerts and suggested actions\")\n",
        "    df_last = df.sort_values(\"time\", ascending=False).head(10)\n",
        "    df_last[\"severity\"] = np.where(df_last[\"stress_index\"] > 0.8, \"high\", \"medium\")\n",
        "    df_last[\"id\"] = \"SAT net\"\n",
        "    df_last[\"time_center\"] = df_last[\"time\"]\n",
        "    alerts_df = df_last[[\"id\", \"time_center\", \"severity\"]]\n",
        "    render_alerts(alerts_df, \"id\", \"time_center\", \"severity\", \"Most stressed recent periods\", \"stress\")\n",
        "\n",
        "    st.markdown(\"#### Animated illustration placeholder\")\n",
        "    st.caption(\"Placeholder for a radar-style animation that brightens when the stress index rises.\")\n",
        "\n",
        "# ------------------------------\n",
        "# Router\n",
        "# ------------------------------\n",
        "\n",
        "if view == \"Overview\":\n",
        "    page_overview()\n",
        "elif view == \"Signal Loss\":\n",
        "    page_signal_loss()\n",
        "elif view == \"Jamming / Interference\":\n",
        "    page_jamming()\n",
        "elif view == \"SLA Breach\":\n",
        "    page_sla()\n",
        "elif view == \"Beam Handover\":\n",
        "    page_handover()\n",
        "elif view == \"Space Weather\":\n",
        "    page_space_weather()\n",
        "elif view == \"Risk-aware Capacity Advisor\":\n",
        "    page_capacity()\n",
        "elif view == \"Stress Index & Joint Risk Radar\":\n",
        "    page_stress()\n",
        "'''\n",
        "\n",
        "# Remove common leading whitespace from app_code_raw\n",
        "app_code = textwrap.dedent(app_code_raw)\n",
        "\n",
        "with open(f\"{DASHBOARD_DIR}/app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"Saved:\", f\"{DASHBOARD_DIR}/app.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjgbkJhxlbwQ",
        "outputId": "0bc6029f-2794-48fa-8b3f-2cc3512ec1f2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# Step 3 - Install streamlit\n",
        "# =======================================================\n",
        "\n",
        "!pip install streamlit -q\n",
        "!python -c \"import streamlit; print('Streamlit version:', streamlit.__version__)\"\n",
        "!python -m streamlit run /content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard/app.py \\\n",
        "    --server.port 8501 --server.address 0.0.0.0 &>/tmp/streamlit.log &\n",
        "!tail -n 50 /tmp/streamlit.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWao10Ixetq5",
        "outputId": "8c8bbeef-f6a2-4428-9d38-64ca2bbd803a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit version: 1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# Step 4 - Install cloudfare\n",
        "# =======================================================\n",
        "# Download cloudflared binary\n",
        "!curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared\n",
        "!chmod +x cloudflared\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b20wiIWUajwT",
        "outputId": "ec6ee06a-fe6b-40cb-d4ed-c1fb097f857d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 39.3M  100 39.3M    0     0  93.7M      0 --:--:-- --:--:-- --:--:-- 93.7M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# Step 5 - Run streamlit\n",
        "# =======================================================\n",
        "\n",
        "!python -m streamlit run /content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard/app.py \\\n",
        "    --server.port 8501 --server.address 0.0.0.0 &>/tmp/streamlit.log &\n",
        "\n",
        "!tail -n 50 /tmp/streamlit.log\n"
      ],
      "metadata": {
        "id": "rlvUbAe1a2px"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 50 /tmp/streamlit.log\n",
        "\n",
        "!ps aux | grep streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN2HueMza4-i",
        "outputId": "d68b6d28-a971-4567-d62a-93fcdbf5a8b4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "2025-12-03 10:53:48.294 Port 8501 is already in use\n",
            "root       18708  6.2  0.5 232440 70220 ?        S    10:53   0:02 python3 -m streamlit run /content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard/app.py --server.port 8501 --server.address 0.0.0.0\n",
            "root       18949  0.0  0.0   7376  3592 ?        S    10:53   0:00 /bin/bash -c ps aux | grep streamlit\n",
            "root       18951  0.0  0.0   6484  2528 ?        S    10:53   0:00 grep streamlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# Step 6 - Launch cloudfare\n",
        "# =======================================================\n",
        "\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBKwCG46a62q",
        "outputId": "b102c93f-5965-4f4a-d05f-a17051cdf9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m2025-12-03T10:53:58Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-12-03T10:53:58Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m |  https://qty-northwest-psychiatry-pas.trycloudflare.com                                    |\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: b7be4573-1b0f-455a-b45d-af404bd37b0a\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-12-03T10:54:03Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167\n",
            "2025/12/03 10:54:03 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-12-03T10:54:04Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mb3c715dd-6fbe-4322-957e-8decf98b6506 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mlocation=\u001b[0miad10 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ]
    }
  ]
}