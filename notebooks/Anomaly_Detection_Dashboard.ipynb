{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53035,"status":"ok","timestamp":1766573454007,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"8H5v1TN2A9-P","outputId":"c9b43a4d-d0f8-48cd-8b20-6e0924d451f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h/bin/bash: line 1: Install: command not found\n","Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.2)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n","Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2025.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n","Drive not mounted, so nothing to flush and unmount.\n","Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard',\n"," ['CIEL2_ManeuverEvents_R1.csv',\n","  'ThrusterTemperaturePIDs.csv',\n","  'AttitudePIDs.csv',\n","  'LabelManeuverEvents.m',\n","  'Archive',\n","  'SESGroundData_Oct-Nov_AS1.xlsx',\n","  'artifacts_signal_loss',\n","  'artifacts_sla',\n","  'artifacts_powerfault',\n","  'space_weather_gfz_kp_ap_2023_v1.csv',\n","  'gfz_kp_ap_2023.csv',\n","  'ses_comm_features.csv',\n","  'ses_clean_10s.parquet',\n","  'ses_comm_anomalies.csv',\n","  'artifacts_jamming',\n","  ' 3_3_SES_Prototype_BeamHandover.ipynb',\n","  'ses_maneuver_features.csv',\n","  'gfz_kp_ap_2012-01-01_2020-02-27.csv',\n","  'ses_spaceweather_dataset.csv',\n","  '3_3_SES_Prototype_SignalLoss.ipynb',\n","  '3_3_SES_Jamming_Interference.ipynb',\n","  '3_3_SES_Space_Weather.ipynb',\n","  '3_3_SES_Prototype_SLA_Proxy.ipynb',\n","  'artifacts_capacity',\n","  '3_3_SES_Risk_Aware_Capacity_Advisor.ipynb',\n","  'artifacts_stress',\n","  '3_3_SES_Prototype_StressIndex.ipynb',\n","  'artifacts_spaceweather',\n","  'dashboard_alert_acks.csv',\n","  'artifacts_handover',\n","  'dashboard_alerts.csv',\n","  'dashboard',\n","  'phase3_ESA-Mission1',\n","  'dashboard_feedback.csv',\n","  'alert_history-2.csv',\n","  'alert_history-3.csv',\n","  'dashboard_alert_history.csv',\n","  'feedback-2.csv',\n","  'Plots And Diagrams.ipynb',\n","  'Anomaly_Detection_Dashboard.ipynb'])"]},"metadata":{},"execution_count":1}],"source":["# =======================================================\n","# Step 1 - Environment setup (Colab)\n","# =======================================================\n","!pip install --quiet --upgrade pip\n","!pip install --quiet streamlit plotly pandas numpy pyngrok\n","!Install libraries\n","!pip install --upgrade pip\n","!pip install streamlit plotly pandas pyngrok\n","!pip install textblob\n","\n","import os\n","from google.colab import drive\n","\n","drive.flush_and_unmount()\n","\n","#rm -rf /content/drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","BASE_DIR = \"/content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses\"\n","DASHBOARD_DIR = os.path.join(BASE_DIR, \"dashboard\")\n","os.makedirs(DASHBOARD_DIR, exist_ok=True)\n","DASHBOARD_DIR, os.listdir(BASE_DIR)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1766573458854,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"hv9PAKsLBeOK","outputId":"d6606569-bda0-409d-ec1c-d60dda2ebb4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["alignment_map.png\n","app.py\n","assets\n","contribution_map.png\n","dashboard_framework_diagram.png\n","Figure_13_System_Design_XAI_Framework.png\n","figure_3x_architecture.png\n","figure6_pr_auc_bar.png\n","figure7_sentiment_hist.png\n","figure8_ack_rate_by_usecase.png\n","Figure_9_2_Foundations_of_XAI.png\n","Figure_9_3_Evolution_of_Satellite_AD.png\n","Figure_9_4_Human_AI_Loop.png\n","Figure_LR_Gaps_to_Thesis.png\n","Figure_LR_Phase_Flow.png\n","Figure_LR_Process.png\n","Figure_LR_Themes.png\n","methodology_diagram.png\n","phase0_data_acquisition_diagram.png\n","Phase0_Data_Acquisition_OptionC\n","Phase0_Data_Acquisition_OptionC.png\n","Phase0_Data_Strategy.png\n","Phase0_to_Dashboard_Traceability.png\n","Research_objectives_xai_framework.pdf\n","Theoretical_Framework_Diagram.png\n","XAI_Framework_DarkBlue.png.png\n"," 3_3_SES_Jamming_Interference.ipynb\n","' 3_3_SES_Prototype_BeamHandover.ipynb'\n"," 3_3_SES_Prototype_SignalLoss.ipynb\n"," 3_3_SES_Prototype_SLA_Proxy.ipynb\n"," 3_3_SES_Prototype_StressIndex.ipynb\n"," 3_3_SES_Risk_Aware_Capacity_Advisor.ipynb\n"," 3_3_SES_Space_Weather.ipynb\n"," alert_history-2.csv\n"," alert_history-3.csv\n"," Anomaly_Detection_Dashboard.ipynb\n"," Archive\n"," artifacts_capacity\n"," artifacts_handover\n"," artifacts_jamming\n"," artifacts_powerfault\n"," artifacts_signal_loss\n"," artifacts_sla\n"," artifacts_spaceweather\n"," artifacts_stress\n"," AttitudePIDs.csv\n"," CIEL2_ManeuverEvents_R1.csv\n"," dashboard\n"," dashboard_alert_acks.csv\n"," dashboard_alert_history.csv\n"," dashboard_alerts.csv\n"," dashboard_feedback.csv\n"," feedback-2.csv\n"," gfz_kp_ap_2012-01-01_2020-02-27.csv\n"," gfz_kp_ap_2023.csv\n"," LabelManeuverEvents.m\n"," phase3_ESA-Mission1\n","'Plots And Diagrams.ipynb'\n"," ses_clean_10s.parquet\n"," ses_comm_anomalies.csv\n"," ses_comm_features.csv\n"," SESGroundData_Oct-Nov_AS1.xlsx\n"," ses_maneuver_features.csv\n"," ses_spaceweather_dataset.csv\n"," space_weather_gfz_kp_ap_2023_v1.csv\n"," ThrusterTemperaturePIDs.csv\n"]}],"source":["!ls \"$DASHBOARD_DIR\"\n","\n","!ls \"$BASE_DIR\""]},{"cell_type":"markdown","metadata":{"id":"xMbqovEMCGbq"},"source":["# Nova sec√ß√£o"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":791,"status":"ok","timestamp":1766573467211,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"M3oCWt8w8za4","outputId":"a9bbe88a-f2d3-400b-9c3d-bde51cb2fa0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved: /content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard/app.py\n"]}],"source":["import os, textwrap\n","from pathlib import Path\n","\n","BASE_DIR = \"/content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses\"\n","DASHBOARD_DIR = os.path.join(BASE_DIR, \"dashboard\")\n","os.makedirs(DASHBOARD_DIR, exist_ok=True)\n","\n","app_code_raw = '''\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","import plotly.express as px\n","import datetime as dt\n","from functools import lru_cache\n","import requests\n","import json\n","import textwrap\n","\n","# ------------------------------\n","# Paths and global constants\n","# ------------------------------\n","\n","BASE_DIR = Path(__file__).resolve().parent.parent\n","FEEDBACK_CSV = BASE_DIR / \"dashboard_feedback.csv\"\n","ALERT_HISTORY_CSV = BASE_DIR / \"dashboard_alert_history.csv\"\n","#ALERTS_CSV = BASE_DIR / \"alerts_history.csv\"\n","###Apagar a frase em cima\n","\n","CODE_REPO_URL = \"https://github.com/AmadizSabino/xAI-for-Satellite-Networks\"\n","THESIS_URL = \"https://your-thesis-link\"\n","\n","# ------------------------------\n","# Translation engine (local dictionaries)\n","# ------------------------------\n","\n","LANG_CODES = {\n","    \"English\": \"en\",\n","    \"Portugu√™s\": \"pt\",\n","    \"Fran√ßais\": \"fr\",\n","    \"Espa√±ol\": \"es\",\n","}\n","\n","LOCAL_TRANSLATIONS = {\n","    \"pt\": {\n","        \"Anomaly Dashboard\": \"Painel de Anomalias\",\n","        \"Language\": \"Idioma\",\n","        \"Overview\": \"Vis√£o geral\",\n","        \"Signal Loss\": \"Perda de Sinal\",\n","        \"Jamming / Interference\": \"Jamming / Interfer√™ncia\",\n","        \"SLA Breach\": \"Viola√ß√£o de SLA\",\n","        \"Beam Handover\": \"Mudan√ßa de Feixe\",\n","        \"Space Weather\": \"Clima Espacial\",\n","        \"Risk-aware Capacity Advisor\": \"Conselheiro de Capacidade Sens√≠vel ao Risco\",\n","        \"Stress Index & Joint Risk Radar\": \"√çndice de Stress e Radar de Risco Conjunto\",\n","        \"Alert Analytics (Thesis Mode)\": \"Anal√≠tica de Alertas (Modo Tese)\",\n","        \"Feedback Analytics (Thesis Mode)\": \"Anal√≠tica de Feedback (Modo Tese)\",\n","        \"Academic mode (show literature links)\": \"Modo acad√©mico (mostrar refer√™ncias)\",\n","        \"Time window\": \"Janela temporal\",\n","        \"Last 24h\": \"√öltimas 24h\",\n","        \"Last 7 days\": \"√öltimos 7 dias\",\n","        \"Full dataset\": \"Conjunto de dados completo\",\n","        \"Acknowledge\": \"Reconhecer\",\n","        \"Alerts and suggested actions ‚Äì recent high-risk windows\":\n","            \"Alertas e a√ß√µes sugeridas ‚Äì janelas recentes de alto risco\",\n","        \"Current space weather (live NOAA Kp index)\":\n","            \"Clima espacial atual (√≠ndice Kp da NOAA em tempo real)\",\n","        \"Earth in real time (NOAA) ‚Äì external view\":\n","            \"Terra em tempo real (NOAA) ‚Äì vista externa\",\n","        \"Open NOAA Earth in Real Time\": \"Abrir NOAA Earth in Real Time\",\n","    },\n","    \"fr\": {\n","        \"Anomaly Dashboard\": \"Tableau de bord des anomalies\",\n","        \"Overview\": \"Vue d‚Äôensemble\",\n","        \"Signal Loss\": \"Perte de signal\",\n","        \"Jamming / Interference\": \"Brouillage / Interf√©rences\",\n","        \"SLA Breach\": \"Violation de SLA\",\n","        \"Beam Handover\": \"Changement de faisceau\",\n","        \"Space Weather\": \"M√©t√©o spatiale\",\n","        \"Risk-aware Capacity Advisor\": \"Conseiller capacit√© sensible au risque\",\n","        \"Stress Index & Joint Risk Radar\":\n","            \"Indice de stress et radar de risque conjoint\",\n","        \"Alert Analytics (Thesis Mode)\":\n","            \"Analyse des alertes (mode th√®se)\",\n","        \"Feedback Analytics (Thesis Mode)\":\n","            \"Analyse des retours (mode th√®se)\",\n","        \"Acknowledge\": \"Accuser r√©ception\",\n","    },\n","    \"es\": {\n","        \"Anomaly Dashboard\": \"Panel de anomal√≠as\",\n","        \"Overview\": \"Resumen\",\n","        \"Signal Loss\": \"P√©rdida de se√±al\",\n","        \"Jamming / Interference\": \"Interferencia / Jamming\",\n","        \"SLA Breach\": \"Incumplimiento de SLA\",\n","        \"Beam Handover\": \"Transferencia de haz\",\n","        \"Space Weather\": \"Clima espacial\",\n","        \"Risk-aware Capacity Advisor\": \"Asesor de capacidad consciente del riesgo\",\n","        \"Stress Index & Joint Risk Radar\":\n","            \"√çndice de estr√©s y radar de riesgo conjunto\",\n","        \"Alert Analytics (Thesis Mode)\":\n","            \"Anal√≠tica de alertas (modo tesis)\",\n","        \"Feedback Analytics (Thesis Mode)\":\n","            \"Anal√≠tica de feedback (modo tesis)\",\n","        \"Acknowledge\": \"Reconocer\",\n","    },\n","}\n","\n","@lru_cache(maxsize=4096)\n","def tr(text: str) -> str:\n","    \"\"\"Translate using simple local dictionaries; fall back to English text.\"\"\"\n","    lang_code = st.session_state.get(\"lang_code\", \"en\")\n","    if lang_code == \"en\":\n","        return text\n","    mapping = LOCAL_TRANSLATIONS.get(lang_code, {})\n","    return mapping.get(text, text)\n","\n","# ------------------------------\n","# Literature notes (Academic mode)\n","# ------------------------------\n","\n","LIT_NOTES = {\n","    \"overview\": (\n","        \"Human-centred AI and operator-in-the-loop tooling inspired by \"\n","        \"Amershi et al. (2019) and Tjoa & Guan (2020).\"\n","    ),\n","    \"signal_loss\": (\n","        \"SHAP-based telemetry explanations related to Cu√©llar et al. (2024) \"\n","        \"on satellite telemetry anomaly explanation.\"\n","    ),\n","    \"jamming\": (\n","        \"Interference detection and feature relevance inspired by \"\n","        \"Li (2023) and Tritscher (2023) on RF anomaly detection.\"\n","    ),\n","    \"sla\": (\n","        \"Early-warning SLA risk modelling aligned with service-quality \"\n","        \"monitoring literature in satellite networks.\"\n","    ),\n","    \"handover\": (\n","        \"Beam handover quality monitoring connects to mobility QoS work \"\n","        \"in satellite and 5G networks.\"\n","    ),\n","    \"spaceweather\": (\n","        \"Space-weather risk combined with station-keeping manoeuvres uses \"\n","        \"NOAA indices as in Franco de la Pe√±a et al. (2025).\"\n","    ),\n","    \"capacity\": (\n","        \"Risk-aware capacity advisor and risk_index introduced in \"\n","        \"Sabino (2025) as a way to merge utilisation, demand forecasts \"\n","        \"and explainability signals into a single operational score.\"\n","    ),\n","    \"stress\": (\n","        \"Stress index and joint risk radar proposed by Sabino et al. (2025), \"\n","        \"inspired by system-level explanations in Iino et al. (2024).\"\n","    ),\n","    \"alerts\": (\n","        \"Alert analytics used to study alert fatigue and human factors \"\n","        \"following Tjoa & Guan (2020).\"\n","    ),\n","    \"feedback\": (\n","        \"Feedback analytics supports formative evaluation and usability \"\n","        \"assessment in line with human-centred XAI guidelines \"\n","        \"by Amershi et al. (2019).\"\n","    ),\n","}\n","\n","def lit_expander(key: str):\n","    if not st.session_state.get(\"academic_mode\", False):\n","        return\n","    note = LIT_NOTES.get(key)\n","    if note:\n","        with st.expander(\"Literature context\", expanded=False):\n","            st.caption(note)\n","\n","# ------------------------------\n","# IO helpers\n","# ------------------------------\n","\n","def load_csv(relative_paths, parse_dates=None):\n","    paths = relative_paths if isinstance(relative_paths, (list, tuple)) else [relative_paths]\n","    for rel in paths:\n","        p = BASE_DIR / rel\n","        if p.exists():\n","            try:\n","                return pd.read_csv(p, parse_dates=parse_dates)\n","            except Exception:\n","                return None\n","    return None\n","\n","def load_image_path(relative_paths):\n","    paths = relative_paths if isinstance(relative_paths, (list, tuple)) else [relative_paths]\n","    for rel in paths:\n","        p = BASE_DIR / rel\n","        if p.exists():\n","            return str(p)\n","    return None\n","\n","def append_feedback(row: dict):\n","    try:\n","        if FEEDBACK_CSV.exists():\n","            existing = pd.read_csv(FEEDBACK_CSV)\n","            existing = pd.concat([existing, pd.DataFrame([row])], ignore_index=True)\n","            existing.to_csv(FEEDBACK_CSV, index=False)\n","        else:\n","            pd.DataFrame([row]).to_csv(FEEDBACK_CSV, index=False)\n","    except Exception:\n","        st.warning(\"Could not persist feedback to CSV in this environment.\")\n","\n","def append_alert_history(rows: list):\n","    if not rows:\n","        return\n","    try:\n","        new_df = pd.DataFrame(rows)\n","        if ALERT_HISTORY_CSV.exists():\n","            old = pd.read_csv(ALERT_HISTORY_CSV)\n","            merged = pd.concat([old, new_df], ignore_index=True)\n","        else:\n","            merged = new_df\n","        merged.to_csv(ALERT_HISTORY_CSV, index=False)\n","    except Exception:\n","        st.warning(\"Could not persist alert history to CSV in this environment.\")\n","\n","def load_shap_matrix(relative_path):\n","    df = load_csv(relative_path)\n","    if df is None:\n","        return None, None, None\n","    first_col = df.columns[0].lower()\n","    if first_col.startswith(\"unnamed\"):\n","        df = df.set_index(df.columns[0])\n","    feature_names = df.index.tolist()\n","    time_labels = df.columns.tolist()\n","    return df, feature_names, time_labels\n","\n","\n","\n","# ------------------------------\n","# Alerts helpers\n","# ------------------------------\n","def bootstrap_median_ci(values, n_boot=2000, ci=0.95, seed=42):\n","    \"\"\"\n","    Non-parametric bootstrap CI for the median.\n","    Suitable for skewed time-to-ack distributions.\n","    \"\"\"\n","    vals = pd.Series(values).dropna().astype(float).values\n","    if len(vals) < 5:\n","        return None\n","\n","    rng = np.random.default_rng(seed)\n","    n = len(vals)\n","    boots = np.empty(n_boot, dtype=float)\n","\n","    for i in range(n_boot):\n","        sample = rng.choice(vals, size=n, replace=True)\n","        boots[i] = np.median(sample)\n","\n","    alpha = (1 - ci) / 2\n","    lo = float(np.quantile(boots, alpha))\n","    hi = float(np.quantile(boots, 1 - alpha))\n","    return lo, hi\n","\n","\n","\n","\n","# ------------------------------\n","# Time window helpers\n","# ------------------------------\n","\n","def get_time_window_hours():\n","    options_display = [tr(\"Last 24h\"), tr(\"Last 7 days\"), tr(\"Full dataset\")]\n","    current = st.session_state.get(\"time_window_display\", options_display[-1])\n","    try:\n","        idx = options_display.index(current)\n","    except ValueError:\n","        return None\n","    if idx == 0:\n","        return 24\n","    if idx == 1:\n","        return 7 * 24\n","    return None\n","\n","def apply_time_filter(df, time_col):\n","    hours = get_time_window_hours()\n","    if df is None or hours is None or time_col not in df.columns:\n","        return df\n","    latest_time = df[time_col].max()\n","    if pd.isna(latest_time):\n","        return df\n","    window_start = latest_time - pd.Timedelta(hours=hours)\n","    return df[df[time_col].between(window_start, latest_time)].copy()\n","\n","# ------------------------------\n","# Thesis branding\n","# ------------------------------\n","\n","def render_thesis_header():\n","    st.markdown(\n","        \"\"\"\n","        <div style=\"padding:0.4rem 0 0.6rem 0; font-size:0.85rem; opacity:0.90;\">\n","          <b>University of Hull ‚Äì MSc Artificial Intelligence</b><br>\n","          Explainable AI for Satellite Networks ‚Äì XAI Prototype Dashboard<br>\n","          Author: <b>Amadiz Sabino</b> ¬∑ Organisation: SES ¬∑ Academic year: 2025\n","        </div>\n","        \"\"\",\n","        unsafe_allow_html=True,\n","    )\n","\n","def render_thesis_footer():\n","    st.markdown(\n","        \"\"\"\n","        <hr style=\"margin-top:2rem; margin-bottom:0.4rem;\" />\n","        \"\"\",\n","        unsafe_allow_html=True,\n","    )\n","    st.markdown(\n","        \"Prototype developed as part of the MSc AI thesis to evaluate \"\n","        \"Explainable AI techniques for anomaly detection in satellite networks. \"\n","        \"For methodology and evaluation details, please refer to the written dissertation.\"\n","    )\n","\n","def render_academic_banner():\n","    if not st.session_state.get(\"academic_mode\", False):\n","        return\n","    st.markdown(\n","        \"\"\"\n","        <div style=\"\n","            background-color:#1d4ed8;\n","            color:white;\n","            padding:0.6rem 1.0rem;\n","            border-radius:0 0 0.75rem 0.75rem;\n","            font-size:0.85rem;\n","            margin-bottom:1.0rem;\">\n","          <b>ACADEMIC MODE ENABLED</b><br/>\n","          Explanations include references to the literature review (Cu√©llar 2024, Iino 2024,\n","          Li 2023, Tritscher 2023, Franco de la Pe√±a 2025, Sabino 2025).\n","        </div>\n","        \"\"\",\n","        unsafe_allow_html=True,\n","    )\n","\n","# ------------------------------\n","# SHAP helper\n","# ------------------------------\n","\n","def add_shap_hover(fig, x_label=\"time\", y_label=\"feature\", context_note=None):\n","    hover = f\"{x_label}=%{{x}}<br>{y_label}=%{{y}}<br>SHAP=%{{z:.3f}}\"\n","    if st.session_state.get(\"academic_mode\", False) and context_note:\n","        hover += f\"<br><br>{context_note}\"\n","    hover += \"<extra></extra>\"\n","    fig.update_traces(hovertemplate=hover)\n","    fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","    return fig\n","\n","# ------------------------------\n","# Alerts rendering + 3D button CSS\n","# ------------------------------\n","\n","def render_alerts(df, id_col, time_col, severity_col, title, usecase_key, max_rows=3):\n","    st.markdown(f\"### {title}\")\n","\n","    #now_utc = pd.Timestamp.utcnow().tz_localize(\"UTC\")\n","    now_utc = pd.Timestamp.now(tz=\"UTC\")\n","    acked_at_utc = now_utc.isoformat()\n","\n","    # 3D-like style for Streamlit buttons (including Acknowledge)\n","    st.markdown(\n","        \"\"\"\n","        <style>\n","        div[data-testid=\"stButton\"] > button {\n","          background: linear-gradient(180deg,#22c55e,#16a34a);\n","          border: none;\n","          border-radius: 999px;\n","          padding: 0.25rem 0.9rem;\n","          color: white;\n","          font-size: 0.8rem;\n","          box-shadow: 0 3px 0 #15803d;\n","        }\n","        div[data-testid=\"stButton\"] > button:active {\n","          box-shadow: 0 1px 0 #15803d;\n","          transform: translateY(2px);\n","        }\n","        </style>\n","        \"\"\",\n","        unsafe_allow_html=True,\n","    )\n","\n","    if \"acked_alerts\" not in st.session_state:\n","        st.session_state[\"acked_alerts\"] = []\n","\n","    if \"logged_alert_keys\" not in st.session_state:\n","        st.session_state[\"logged_alert_keys\"] = {}\n","\n","    acked = set(st.session_state[\"acked_alerts\"])\n","    logged = st.session_state[\"logged_alert_keys\"]\n","\n","    if df is None:\n","        demo = pd.DataFrame(\n","            {\n","                id_col: [f\"ALERT-{usecase_key.upper()}-{i+1}\" for i in range(3)],\n","                time_col: pd.date_range(\"2021-11-01\", periods=3, freq=\"H\"),\n","                severity_col: [\"high\", \"medium\", \"medium\"],\n","            }\n","        )\n","        df_to_show = demo\n","    else:\n","        df_to_show = df.sort_values(time_col, ascending=False).head(max_rows)\n","\n","    def make_key(row):\n","        return f\"{usecase_key}:{row[id_col]}:{row[time_col]}\"\n","\n","    mask = []\n","    for _, r in df_to_show.iterrows():\n","        if make_key(r) not in acked:\n","            mask.append(True)\n","        else:\n","            mask.append(False)\n","    df_to_show = df_to_show[mask]\n","\n","    if df_to_show.empty:\n","        st.success(\"No anomalies in this window ‚Äì system healthy.\")\n","        return\n","\n","    rows_to_persist = []\n","\n","    for i, (_, row) in enumerate(df_to_show.iterrows()):\n","        key = make_key(row)\n","        sev = str(row[severity_col]).lower()\n","\n","        # If this alert has never been logged, log a non-acked entry\n","        if key not in logged:\n","            rows_to_persist.append(\n","                {\n","                    \"usecase\": usecase_key,\n","                    \"alert_id\": row[id_col],\n","                    \"time_center\": row[time_col],\n","                    \"severity\": sev,\n","                    \"acked_at_utc\": None,\n","                }\n","            )\n","            logged[key] = False  # seen but not acknowledged yet\n","\n","        badge_color = \"#f97316\"\n","        if sev == \"high\":\n","            badge_color = \"#dc2626\"\n","        elif sev == \"medium\":\n","            badge_color = \"#fb923c\"\n","        elif sev == \"low\":\n","            badge_color = \"#16a34a\"\n","\n","        card_bg = \"#ffffff\"\n","        border_color = \"#e5e7eb\"\n","\n","        st.markdown(\n","            f\"\"\"\n","            <div style=\"\n","                border: 1px solid {border_color};\n","                border-radius: 0.6rem;\n","                padding: 0.75rem 0.9rem;\n","                margin-bottom: 0.6rem;\n","                background-color: {card_bg};\n","                box-shadow: 0 1px 2px rgba(15,23,42,0.08);\n","            \">\n","              <div style=\"display:flex; justify-content:space-between; align-items:center;\">\n","                <div style=\"font-weight:600;\">{row[id_col]}</div>\n","                <span style=\"\n","                    font-size:0.75rem;\n","                    padding: 0.15rem 0.5rem;\n","                    border-radius: 999px;\n","                    background-color:{badge_color};\n","                    color:white;\n","                    text-transform:uppercase;\n","                    letter-spacing:0.04em;\n","                \">{sev}</span>\n","              </div>\n","              <div style=\"font-size:0.8rem; margin-top:0.15rem; opacity:0.8;\">\n","                üì° Time: {row[time_col]}\n","              </div>\n","            \"\"\",\n","            unsafe_allow_html=True,\n","        )\n","\n","        col_a, col_b = st.columns([1, 2])\n","        with col_a:\n","            if st.button(tr(\"Acknowledge\"), key=f\"{usecase_key}_ack_{i}\"):\n","                if key not in acked:\n","                    st.session_state[\"acked_alerts\"].append(key)\n","                    # Log an acknowledged entry\n","                    rows_to_persist.append(\n","                        {\n","                            \"usecase\": usecase_key,\n","                            \"alert_id\": row[id_col],\n","                            \"time_center\": row[time_col],\n","                            \"severity\": sev,\n","                            \"acked_at_utc\": pd.Timestamp.utcnow().isoformat(),\n","                        }\n","                    )\n","                    logged[key] = True\n","        with col_b:\n","            st.caption(\n","                \"Typical action: open NOC ticket, attach supporting evidence, \"\n","                \"and notify the on-call engineer.\"\n","            )\n","\n","        st.markdown(\"</div>\", unsafe_allow_html=True)\n","\n","    if rows_to_persist:\n","        append_alert_history(rows_to_persist)\n","\n","# ------------------------------\n","# Page config + sidebar\n","# ------------------------------\n","\n","st.set_page_config(page_title=\"Satellite Anomaly Dashboard\", layout=\"wide\")\n","\n","st.markdown(\n","    \"\"\"\n","    <style>\n","    @media (max-width: 768px) {\n","        .block-container {\n","            padding-left: 0.8rem;\n","            padding-right: 0.8rem;\n","        }\n","    }\n","    </style>\n","    \"\"\",\n","    unsafe_allow_html=True,\n",")\n","\n","st.sidebar.title(tr(\"Anomaly Dashboard\"))\n","\n","academic_mode = st.sidebar.checkbox(tr(\"Academic mode (show literature links)\"), value=True)\n","st.session_state[\"academic_mode\"] = academic_mode\n","\n","lang_label = st.sidebar.selectbox(\"Language\", list(LANG_CODES.keys()), index=0)\n","st.session_state[\"lang_code\"] = LANG_CODES[lang_label]\n","\n","view = st.sidebar.radio(\n","    \"Select a view\",\n","    [\n","        tr(\"Overview\"),\n","        tr(\"Signal Loss\"),\n","        tr(\"Jamming / Interference\"),\n","        tr(\"SLA Breach\"),\n","        tr(\"Beam Handover\"),\n","        tr(\"Space Weather\"),\n","        tr(\"Risk-aware Capacity Advisor\"),\n","        tr(\"Stress Index & Joint Risk Radar\"),\n","        tr(\"Alert Analytics (Thesis Mode)\"),\n","        tr(\"Feedback Analytics (Thesis Mode)\"),\n","    ],\n",")\n","\n","with st.sidebar.expander(\"Demo filters\", expanded=True):\n","    st.caption(\"In a live system these would filter the underlying data.\")\n","\n","satellite = st.sidebar.selectbox(\n","    \"Satellite (aggregated data)\", [\"M003\", \"M008\", \"M015\", \"M017\", \"ALL\"]\n",")\n","\n","time_window_options = [tr(\"Last 24h\"), tr(\"Last 7 days\"), tr(\"Full dataset\")]\n","time_window_display = st.sidebar.selectbox(\"Time window\", time_window_options, index=2)\n","st.session_state[\"time_window_display\"] = time_window_display\n","\n","# ------------------------------\n","# Overview page\n","# ------------------------------\n","\n","def page_overview():\n","    render_academic_banner()\n","    col_left, col_right = st.columns([2, 1])\n","\n","    with col_left:\n","        st.title(\"Explainable AI for Satellite Networks Anomaly Detection\")\n","        render_thesis_header()\n","\n","        st.markdown(\"---\")\n","        st.subheader(\"Purpose of this prototype\")\n","        st.markdown(\n","            \"\"\"\n","            Monitoring based on ground telemetry, space weather and SLA metrics.\n","            The goal is to give the Network Operations Center early insight into\n","            issues that affect availability and customer experience.\n","            \"\"\"\n","        )\n","\n","        st.markdown(\"---\")\n","        st.subheader(\"What this prototype does\")\n","        st.markdown(\n","            \"\"\"\n","            - Tracks a set of anomaly use cases: signal loss, jamming or interference,\n","              SLA breach, beam handover issues, space weather maneuver risk,\n","              capacity pressure and a combined stress index.\n","            - Uses historical SES data to learn what healthy behaviour looks like,\n","              then scores new windows for risk.\n","            - Uses explainable AI (mainly SHAP heatmaps) so operators can see **why**\n","              a window is flagged.\n","            \"\"\"\n","        )\n","\n","        st.markdown(\"---\")\n","        st.subheader(\"High level anomaly detection performance (test windows)\")\n","\n","        with st.expander(\"How to read these metrics\", expanded=False):\n","            st.markdown(\n","                \"\"\"\n","                - **PR-AUC (Precision‚ÄìRecall area)** ‚Äì how well the model lifts true\n","                  anomalies above noise. This is the main metric for rare events such\n","                  as signal loss or SLA breach.\n","                - **ROC-AUC** ‚Äì overall ability to separate normal vs anomalous windows\n","                  across thresholds. Can look optimistic when anomalies are very rare.\n","                - **Event precision / recall** ‚Äì precision asks *of the alerts raised,\n","                  how many were real?* Recall asks *of all real events, how many did we\n","                  catch?*  In this prototype the models are tuned towards **high precision** so\n","                  that operators can trust an alert, even if that means some events are\n","                  missed (moderate recall) to avoid flooding the NOC with false positives.\n","                \"\"\"\n","            )\n","\n","        metrics = [\n","            (\"Signal Loss model\", 0.72, 0.83, 0.93, 0.13),\n","            (\"SLA early warning\", 0.25, 0.86, 1.00, 0.03),\n","            (\"Beam Handover anomalies\", 0.022, 0.71, 0.50, 0.012),\n","        ]\n","\n","        interpretations = {\n","            \"Signal Loss model\": (\n","                \"The model is strong at prioritising true signal-loss events over noise. \"\n","                \"Most alerts are real (high precision), but it currently only catches a \"\n","                \"subset of all events (moderate recall). It is designed as a conservative \"\n","                \"early-warning signal.\"\n","            ),\n","            \"SLA early warning\": (\n","                \"The model can identify some windows that are at risk of SLA degradation. \"\n","                \"Alerts are very rare but almost always correct (precision close to 1.0), \"\n","                \"so it behaves as a highly conservative early-warning indicator rather \"\n","                \"than a complete SLA monitor.\"\n","            ),\n","            \"Beam Handover anomalies\": (\n","                \"Performance is weaker here, which is expected given the rarity and \"\n","                \"complexity of handover issues. The model can surface some interesting \"\n","                \"cases but still misses most true problems and generates some false \"\n","                \"alerts. This use case is marked as prototype / for further tuning.\"\n","            ),\n","        }\n","\n","        metric_cols = st.columns(len(metrics))\n","        for col, (name, pr, roc, p, r) in zip(metric_cols, metrics):\n","            with col:\n","                st.markdown(f\"**{name}**\")\n","                st.metric(\"PR-AUC\", f\"{pr:.3f}\")\n","                st.metric(\"ROC-AUC\", f\"{roc:.3f}\")\n","                st.caption(f\"Event precision / recall: **{p:.2f} / {r:.2f}**\")\n","                with st.expander(\"Plain-English summary\", expanded=False):\n","                    st.write(interpretations[name])\n","\n","\n","        st.markdown(\"---\")\n","        st.markdown(\"### Radar view of trade-offs between models\")\n","\n","        radar_df = pd.DataFrame(\n","            {\n","                \"metric\": [\"precision\", \"recall\", \"explainability\", \"impact\"],\n","                \"Signal Loss\": [0.93, 0.13, 0.9, 0.8],\n","                \"SLA early warning\": [1.0, 0.03, 0.7, 0.75],\n","                \"Beam Handover\": [0.5, 0.012, 0.6, 0.4],\n","            }\n","        )\n","        radar_melted = radar_df.melt(id_vars=\"metric\", var_name=\"model\", value_name=\"score\")\n","        radar_melted = pd.concat(\n","            [radar_melted, radar_melted[radar_melted[\"metric\"] == \"precision\"]],\n","            ignore_index=True,\n","        )\n","\n","        fig_radar = px.line_polar(\n","            radar_melted,\n","            r=\"score\",\n","            theta=\"metric\",\n","            color=\"model\",\n","            line_close=True,\n","            title=\"Trade-offs between precision, recall, explainability and impact (demo)\",\n","        )\n","        fig_radar.update_traces(fill=\"toself\")\n","        fig_radar.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig_radar, use_container_width=True)\n","\n","        st.markdown(\n","            \"\"\"\n","            This radar view makes the trade-offs between performance, interpretability\n","            and impact explicit, supporting the research questions on realistic,\n","            human-centred deployment scenarios.\n","            \"\"\"\n","        )\n","\n","        lit_expander(\"overview\")\n","\n","\n","        st.markdown(\"---\")\n","        st.subheader(\"Research questions and dashboard mapping\")\n","\n","        rq_rows = [\n","            (\"RQ1 ‚Äì Can XAI make anomaly alerts more interpretable for SES operators?\",\n","             \"Signal Loss, Jamming, SLA, Handover, Space Weather SHAP views.\"),\n","            (\"RQ2 ‚Äì Can system-level views help avoid alert fatigue?\",\n","             \"Stress Index & Joint Risk Radar, Alert Analytics pages.\"),\n","            (\"RQ3 ‚Äì How do operators perceive usefulness and trust in the XAI outputs?\",\n","             \"Overview feedback form + Feedback Analytics page.\"),\n","            (\"RQ4 ‚Äì How do different models trade off precision, recall and interpretability?\",\n","             \"Model metrics and radar view on this page.\"),\n","        ]\n","        rq_df = pd.DataFrame(rq_rows, columns=[\"Research question\", \"Where to look in the dashboard\"])\n","        st.table(rq_df)\n","\n","\n","        st.markdown(\"---\")\n","        st.subheader(\"Prototype feedback (for thesis user study)\")\n","\n","        with st.expander(\"Leave quick feedback about this dashboard\", expanded=False):\n","            role = st.selectbox(\n","                \"Your role (for context)\",\n","                [\"NOC operator\", \"Engineer\", \"Manager\", \"Student / Researcher\", \"Other\"],\n","                index=0,\n","            )\n","            feedback_text = st.text_area(\n","                \"What is most useful? What is confusing or missing?\",\n","                height=120,\n","                key=\"overview_feedback\",\n","            )\n","            col_s1, col_s2, col_s3 = st.columns(3)\n","            with col_s1:\n","                ux_shap = st.slider(\"How helpful are the SHAP explanations? (1‚Äì5)\", 1, 5, 4)\n","            with col_s2:\n","                ux_layout = st.slider(\"How clear is the layout? (1‚Äì5)\", 1, 5, 4)\n","            with col_s3:\n","                ux_trust = st.slider(\"How much would you trust these alerts? (1‚Äì5)\", 1, 5, 4)\n","\n","            impact_estimate = st.selectbox(\n","                \"Rough impact estimate if models were deployed\",\n","                [\n","                    \"Unknown / hard to estimate\",\n","                    \"Minor ‚Äì quality-of-life improvements\",\n","                    \"Moderate ‚Äì minutes of downtime avoided per week\",\n","                    \"High ‚Äì tens of thousands of EUR per year in avoided penalties\",\n","                ],\n","            )\n","\n","            if st.button(\"Record feedback for thesis analysis\"):\n","                if feedback_text.strip():\n","                    row = {\n","                        \"timestamp_utc\": pd.Timestamp.utcnow().isoformat(),\n","                        \"role\": role,\n","                        \"feedback\": feedback_text.strip(),\n","                        \"impact_estimate\": impact_estimate,\n","                        \"ux_shap\": ux_shap,\n","                        \"ux_layout\": ux_layout,\n","                        \"ux_trust\": ux_trust,\n","                        \"satellite_filter\": satellite,\n","                        \"time_window_display\": st.session_state.get(\"time_window_display\"),\n","                    }\n","                    append_feedback(row)\n","                    st.success(\"Feedback stored in CSV for thesis analysis.\")\n","                else:\n","                    st.warning(\"Please write some feedback before submitting.\")\n","\n","    with col_right:\n","        gif_url = \"https://i.gifer.com/AHJv.gif\"\n","        st.image(gif_url, caption=\"Orbital view (www.gifer.com)\", use_container_width=True)\n","\n","    render_thesis_footer()\n","\n","\n","\n","\n","# ------------------------------\n","# Signal Loss page\n","# ------------------------------\n","\n","def page_signal_loss():\n","    render_academic_banner()\n","    st.title(tr(\"Signal Loss\"))\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\"### What this use case monitors\")\n","    st.markdown(\n","        \"The model watches a small set of modem power and quality indicators over time. \"\n","        \"When they drift away from their usual pattern, the window is flagged as a potential \"\n","        \"signal loss scenario.\"\n","    )\n","\n","    st.markdown(\"### Why this matters for operators\")\n","    st.markdown(\n","        \"- Persistent signal loss directly reduces availability and can trigger SLA penalties.\\\\n\"\n","        \"- On a busy beam, an hour of partial outage may affect hundreds of terminals.\\\\n\"\n","        \"- Repeated short drops are hard to see in raw KPIs; automated scoring focuses attention \"\n","        \"on the most risky windows.\"\n","    )\n","\n","    st.markdown(\"### How this prototype works\")\n","    st.markdown(\n","        \"- Features are built from modem IN and OUT power statistics over short windows.\\\\n\"\n","        \"- An autoencoder-style model learns the typical pattern and assigns an anomaly score.\\\\n\"\n","        \"- Thresholding and eventisation convert noisy scores into a small number of alerts.\"\n","    )\n","\n","    col_main, col_side = st.columns([2, 1])\n","    with col_main:\n","        st.markdown(\"### Feature importance over time for Signal Loss model (SHAP values)\")\n","\n","        shap_df, feat_names, time_labels = load_shap_matrix(\n","            \"artifacts_signal_loss/signal_loss_event_shap_values.csv\"\n","        )\n","        if shap_df is not None:\n","            fig_shap = px.imshow(\n","                shap_df,\n","                x=time_labels,\n","                y=feat_names,\n","                aspect=\"auto\",\n","                color_continuous_scale=\"RdBu\",\n","                origin=\"lower\",\n","                labels={\"x\": \"time step within window\", \"y\": \"feature\", \"color\": \"SHAP value\"},\n","                title=\"Signal Loss ‚Äì SHAP heatmap around one event\",\n","            )\n","            fig_shap = add_shap_hover(\n","                fig_shap,\n","                x_label=\"time step\",\n","                y_label=\"feature\",\n","                context_note=(\n","                    \"Per Cu√©llar et al. (2024), brighter cells indicate features that most \"\n","                    \"pushed the model towards the anomalous class.\"\n","                ),\n","            )\n","            st.plotly_chart(fig_shap, use_container_width=True)\n","        else:\n","            event_img = load_image_path(\"artifacts_signal_loss/signal_loss_event_heatmap.png\")\n","            cont_img = load_image_path(\"artifacts_signal_loss/signal_loss_continuous_heatmap.png\")\n","            if event_img:\n","                st.image(event_img, caption=\"Signal Loss ‚Äì SHAP heatmap around one event\", use_container_width=True)\n","            if cont_img:\n","                st.image(cont_img, caption=\"Signal Loss ‚Äì continuous SHAP importance over time\", use_container_width=True)\n","\n","        with st.expander(\"Learn more about how to read this SHAP heatmap\"):\n","            st.markdown(\n","                \"- Rows are modem features (IN/OUT power statistics).\\\\n\"\n","                \"- Columns are time steps in the window.\\\\n\"\n","                \"- Warm colours push the model towards 'signal loss'; cool colours push towards 'normal'.\"\n","            )\n","\n","        lit_expander(\"signal_loss\")\n","\n","        st.markdown(\"#### Example anomaly-score trend\")\n","        scores = load_csv(\"artifacts_signal_loss/test_scores_raw.csv\", parse_dates=[\"timestamp\"])\n","        if scores is not None:\n","            if \"timestamp\" in scores.columns:\n","                scores = scores.rename(columns={\"timestamp\": \"time\"})\n","            if \"proba_raw\" in scores.columns:\n","                scores = scores.rename(columns={\"proba_raw\": \"anomaly_score\"})\n","            if \"time\" in scores.columns and \"anomaly_score\" in scores.columns:\n","                scores = apply_time_filter(scores, \"time\")\n","                scores = scores.sort_values(\"time\").tail(600)\n","                fig = px.line(\n","                    scores,\n","                    x=\"time\",\n","                    y=\"anomaly_score\",\n","                    title=\"Recent signal-loss anomaly scores\",\n","                )\n","                fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","                st.plotly_chart(fig, use_container_width=True)\n","        else:\n","            st.caption(\"Signal-loss scores CSV not found; trend chart skipped in this environment.\")\n","\n","    with col_side:\n","        gif_url = \"https://i.gifer.com/K6mM.gif\"\n","        st.image(gif_url, caption=\"Signal Loss illustration\", use_container_width=True)\n","\n","        events = load_csv(\n","            [\"artifacts_signal_loss/test_eventized_scores.csv\", \"artifacts_signal_loss/test_scores.csv\"],\n","            parse_dates=[\"t_start\", \"t_end\"],\n","        )\n","        alerts_df = None\n","        if events is not None:\n","            events[\"time_center\"] = events[\"t_start\"]\n","            events[\"severity\"] = np.where(events.get(\"label\", 1) == 1, \"high\", \"medium\")\n","            events[\"id\"] = events.get(\"modem\", \"Unknown modem\")\n","            events = apply_time_filter(events, \"time_center\")\n","            if not events.empty:\n","                alerts_df = events[[\"id\", \"time_center\", \"severity\"]]\n","        render_alerts(\n","            alerts_df,\n","            \"id\",\n","            \"time_center\",\n","            \"severity\",\n","            \"Alerts and suggested actions ‚Äì recent high-risk windows\",\n","            \"signal_loss\",\n","        )\n","        st.markdown(\n","            \"- Correlate with weather, maintenance and pointing information.\\\\n\"\n","            \"- If multiple modems on the same beam are affected, escalate as RF impairment.\\\\n\"\n","            \"- If a single modem is affected, open a customer ticket and check terminal side first.\"\n","        )\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Jamming page\n","# ------------------------------\n","\n","def page_jamming():\n","    render_academic_banner()\n","    st.title(tr(\"Jamming / Interference\"))\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\"### What this use case monitors\")\n","    st.markdown(\n","        \"The jamming detector looks for unusual energy patterns in a subset of modem outputs. \"\n","        \"Instead of analysing full spectra, it uses modem statistics as a proxy for interference \"\n","        \"on the uplink or downlink.\"\n","    )\n","\n","    st.markdown(\"### Why this matters for operators\")\n","    st.markdown(\n","        \"- Intentional jamming can degrade whole beams and affect many customers at once.\\\\n\"\n","        \"- Early detection allows the NOC to trigger geolocation or reconfigure beams.\\\\n\"\n","        \"- Without automation, weak but persistent interferers can remain unnoticed for hours.\"\n","    )\n","\n","    st.markdown(\"### How this prototype works\")\n","    st.markdown(\n","        \"- An unsupervised model learns the joint behaviour of communication channels in quiet periods.\\\\n\"\n","        \"- Windows where many channels move together in an unusual way get a high anomaly score.\\\\n\"\n","        \"- SHAP explanations highlight which channels and time slices drove the alarm.\"\n","    )\n","\n","    col_main, col_side = st.columns([2, 1])\n","    with col_main:\n","        st.markdown(\"### Feature importance over time for Jamming model (SHAP values)\")\n","\n","        shap_df, feat_names, time_labels = load_shap_matrix(\n","            \"artifacts_jamming/jamming_event_shap_values.csv\"\n","        )\n","        if shap_df is not None:\n","            fig_shap = px.imshow(\n","                shap_df,\n","                x=time_labels,\n","                y=feat_names,\n","                aspect=\"auto\",\n","                color_continuous_scale=\"RdBu\",\n","                origin=\"lower\",\n","                labels={\"x\": \"time step within window\", \"y\": \"metric / modem\", \"color\": \"SHAP value\"},\n","                title=\"Jamming ‚Äì SHAP heatmap around a suspected event\",\n","            )\n","            fig_shap = add_shap_hover(\n","                fig_shap,\n","                x_label=\"time step\",\n","                y_label=\"metric\",\n","                context_note=\"Related to Li (2023) and Tritscher (2023) on interference anomalies.\",\n","            )\n","            st.plotly_chart(fig_shap, use_container_width=True)\n","        else:\n","            event_img = load_image_path(\"artifacts_jamming/jamming_event_heatmap.png\")\n","            cont_img = load_image_path(\"artifacts_jamming/jamming_continuous_heatmap.png\")\n","            if event_img:\n","                st.image(event_img, caption=\"Jamming ‚Äì SHAP heatmap around a suspected event\", use_container_width=True)\n","            if cont_img:\n","                st.image(cont_img, caption=\"Jamming ‚Äì continuous SHAP importance over time\", use_container_width=True)\n","\n","        with st.expander(\"Learn more about how to read this SHAP heatmap\"):\n","            st.markdown(\n","                \"- Look for blocks of warm cells across several modems at the same time: \"\n","                \"these often correspond to wide-band interference.\\\\n\"\n","                \"- Narrow warm bands in a single row may indicate a localised carrier issue.\\\\n\"\n","                \"- Cool regions show features that argued against a jamming interpretation.\"\n","            )\n","\n","        lit_expander(\"jamming\")\n","\n","    with col_side:\n","        events = load_csv(\"artifacts_jamming/test_eventized_scores.csv\", parse_dates=[\"t_start\", \"t_end\"])\n","        alerts_df = None\n","        if events is not None:\n","            events[\"time_center\"] = events[\"t_start\"]\n","            events[\"severity\"] = np.where(events.get(\"label\", 1) == 1, \"high\", \"medium\")\n","            events[\"id\"] = events.get(\"beam\", \"Unknown beam\")\n","            events = apply_time_filter(events, \"time_center\")\n","            if not events.empty:\n","                alerts_df = events[[\"id\", \"time_center\", \"severity\"]]\n","        render_alerts(\n","            alerts_df,\n","            \"id\",\n","            \"time_center\",\n","            \"severity\",\n","            \"Alerts and suggested actions ‚Äì recent high-risk windows\",\n","            \"jamming\",\n","        )\n","        st.markdown(\n","            \"- Cross-check with spectrum monitoring tools and confirm on a waterfall view.\\\\n\"\n","            \"- Start geolocation if multiple beams show correlated interference.\\\\n\"\n","            \"- Coordinate with customers to move critical carriers if necessary.\"\n","        )\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# SLA page\n","# ------------------------------\n","\n","def page_sla():\n","    render_academic_banner()\n","    st.title(tr(\"SLA Breach\"))\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\"### What this use case monitors\")\n","    st.markdown(\n","        \"This model watches a throughput proxy KPI and compares it against SLA thresholds \"\n","        \"learned from historical data, aiming to provide early warning.\"\n","    )\n","\n","    st.markdown(\"### Why this matters for operators\")\n","    st.markdown(\n","        \"- SLA violations impact revenue and customer satisfaction.\\\\n\"\n","        \"- For premium customers, 30‚Äì60 minutes of degraded throughput can correspond to \"\n","        \"tens of thousands of euros in penalties.\\\\n\"\n","        \"- Even a small lead time is valuable to reroute traffic or add capacity.\"\n","    )\n","\n","    col_main, col_side = st.columns([2, 1])\n","\n","    with col_main:\n","        st.markdown(\"#### SLA thresholds and breaches\")\n","        sla_df = load_csv(\"artifacts_sla/sla_breach_events.csv\", parse_dates=[\"start\", \"end\"])\n","        if sla_df is not None:\n","            sla_df = apply_time_filter(sla_df, \"start\")\n","            if not sla_df.empty:\n","                fig = px.scatter(\n","                    sla_df.sort_values(\"start\").head(200),\n","                    x=\"start\",\n","                    y=\"duration_s\",\n","                    color=\"severity\" if \"severity\" in sla_df.columns else None,\n","                    title=\"Example windows leading into SLA breaches\",\n","                )\n","                fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","                st.plotly_chart(fig, use_container_width=True)\n","            else:\n","                st.info(\"No SLA breaches in this filtered window ‚Äì system healthy.\")\n","        else:\n","            st.info(\"No SLA breach CSV found in artifacts_sla/. Showing explanations only.\")\n","\n","        st.markdown(\"#### Feature importance over time for SLA risk model (SHAP values)\")\n","\n","        shap_df, feat_names, time_labels = load_shap_matrix(\n","            \"artifacts_sla/sla_event_shap_values.csv\"\n","        )\n","        if shap_df is not None:\n","            fig_shap = px.imshow(\n","                shap_df,\n","                x=time_labels,\n","                y=feat_names,\n","                aspect=\"auto\",\n","                color_continuous_scale=\"RdBu\",\n","                origin=\"lower\",\n","                labels={\"x\": \"time step within window\", \"y\": \"feature\", \"color\": \"SHAP value\"},\n","                title=\"SLA ‚Äì SHAP heatmap around one breach\",\n","            )\n","            fig_shap = add_shap_hover(fig_shap, x_label=\"time step\", y_label=\"feature\")\n","            st.plotly_chart(fig_shap, use_container_width=True)\n","        else:\n","            event_img = load_image_path(\"artifacts_sla/sla_event_heatmap.png\")\n","            cont_img = load_image_path(\"artifacts_sla/sla_continuous_heatmap.png\")\n","            if event_img:\n","                st.image(event_img, caption=\"SLA ‚Äì SHAP heatmap around one breach\", use_container_width=True)\n","            if cont_img:\n","                st.image(cont_img, caption=\"SLA ‚Äì continuous SHAP importance over time\", use_container_width=True)\n","\n","        with st.expander(\"Learn more about how to read this SHAP heatmap\"):\n","            st.markdown(\n","                \"- Dominant rows typically correspond to throughput level, volatility and short-term slope.\\\\n\"\n","                \"- Deep blue patches before a breach show that throughput itself is pushing the model towards the breach class.\\\\n\"\n","                \"- Red spikes on slope indicate sharp drops that the model treats as especially risky.\"\n","            )\n","\n","        lit_expander(\"sla\")\n","\n","    with col_side:\n","        st.markdown(\"#### Alerts and suggested actions\")\n","        sim_key = \"sla_sim_alerts\"\n","        if sim_key not in st.session_state:\n","            st.session_state[sim_key] = []\n","\n","        if st.button(\"Simulate new SLA risk window\"):\n","            st.session_state[sim_key].append(\n","                {\n","                    \"id\": \"SIM-SLA\",\n","                    \"time_center\": pd.Timestamp.utcnow().round(\"S\"),\n","                    \"severity\": \"high\",\n","                }\n","            )\n","            st.info(\"Simulated high-risk SLA window added to the alert list.\")\n","\n","        sla_df = load_csv(\"artifacts_sla/sla_breach_events.csv\", parse_dates=[\"start\", \"end\"])\n","        alerts_df = None\n","        if sla_df is not None:\n","            sla_df = apply_time_filter(sla_df, \"start\")\n","            if not sla_df.empty:\n","                sla_df = sla_df.copy()\n","                sla_df[\"time_center\"] = sla_df[\"start\"]\n","                sla_df[\"severity\"] = np.where(sla_df.get(\"breach_flag\", 1) == 1, \"high\", \"medium\")\n","                sla_df[\"id\"] = sla_df.get(\"kpi_id\", \"SLA throughput\")\n","                alerts_df = sla_df[[\"id\", \"time_center\", \"severity\"]]\n","\n","        if st.session_state[sim_key]:\n","            sim_df = pd.DataFrame(st.session_state[sim_key])\n","            if alerts_df is None:\n","                alerts_df = sim_df\n","            else:\n","                alerts_df = pd.concat([sim_df, alerts_df], ignore_index=True)\n","\n","        render_alerts(\n","            alerts_df,\n","            \"id\",\n","            \"time_center\",\n","            \"severity\",\n","            \"Current SLA risk windows\",\n","            \"sla\",\n","        )\n","\n","        st.markdown(\n","            \"- If predicted breach is local to one beam, check utilisation and consider \"\n","            \"temporary capacity boost.\\\\n\"\n","            \"- If several beams show risk, escalate to network planning and investigate \"\n","            \"ground segment issues.\\\\n\"\n","            \"- For severe risk, each hour of outage can cost roughly 10‚Äì20k EUR in penalties \"\n","            \"and lost business for premium customers.\"\n","        )\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Beam Handover page\n","# ------------------------------\n","\n","def page_handover():\n","    render_academic_banner()\n","    st.title(tr(\"Beam Handover\"))\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\"### What this use case monitors\")\n","    st.markdown(\n","        \"Whenever the satellite or network controller moves a terminal from one beam to another, \"\n","        \"there is a short period where throughput can dip. This model tracks handovers and \"\n","        \"highlights those where throughput drops more than expected or recovers slowly.\"\n","    )\n","\n","    st.markdown(\"### Why this matters for operators\")\n","    st.markdown(\n","        \"- Poorly behaving handovers can create repeated short outages that are hard to diagnose.\\\\n\"\n","        \"- They often only affect mobile or aeronautical customers.\\\\n\"\n","        \"- Early visibility enables targeted tuning of handover parameters.\"\n","    )\n","\n","    col_main, col_side = st.columns([2, 1])\n","\n","    with col_main:\n","        st.markdown(\"### Feature importance over time for Handover model (SHAP values)\")\n","        shap_df, feat_names, time_labels = load_shap_matrix(\n","            \"artifacts_handover/handover_event_shap_values.csv\"\n","        )\n","        if shap_df is not None:\n","            fig_shap = px.imshow(\n","                shap_df,\n","                x=time_labels,\n","                y=feat_names,\n","                aspect=\"auto\",\n","                color_continuous_scale=\"RdBu\",\n","                origin=\"lower\",\n","                labels={\"x\": \"time step within window\", \"y\": \"feature\", \"color\": \"SHAP value\"},\n","                title=\"Beam Handover ‚Äì SHAP heatmap around one anomalous handover\",\n","            )\n","            fig_shap = add_shap_hover(fig_shap, x_label=\"time step\", y_label=\"feature\")\n","            st.plotly_chart(fig_shap, use_container_width=True)\n","        else:\n","            event_img = load_image_path(\"artifacts_handover/handover_event_heatmap.png\")\n","            cont_img = load_image_path(\"artifacts_handover/handover_continuous_heatmap.png\")\n","            if event_img:\n","                st.image(event_img, caption=\"Beam Handover ‚Äì SHAP heatmap around one anomalous handover\", use_container_width=True)\n","            if cont_img:\n","                st.image(cont_img, caption=\"Beam Handover ‚Äì continuous SHAP importance over time\", use_container_width=True)\n","\n","        with st.expander(\"Learn more about how to read this SHAP heatmap\"):\n","            st.markdown(\n","                \"- Features include throughput before and after the handover, drop percentage \"\n","                \"and recovery time.\\\\n\"\n","                \"- Warm regions after the handover mark windows where the model is concerned \"\n","                \"about slow or incomplete recovery.\"\n","            )\n","\n","        lit_expander(\"handover\")\n","\n","    with col_side:\n","        events = load_csv(\"artifacts_handover/handover_table.csv\", parse_dates=[\"t\"])\n","        alerts_df = None\n","        if events is not None:\n","            events = events.tail(200)\n","            events[\"time_center\"] = events[\"t\"]\n","            events[\"severity\"] = np.where(events[\"drop_pct\"].abs() > 0.05, \"high\", \"medium\")\n","            events[\"id\"] = events.get(\"beam_id\", \"Unknown beam\")\n","            events = apply_time_filter(events, \"time_center\")\n","            if not events.empty:\n","                alerts_df = events[[\"id\", \"time_center\", \"severity\"]]\n","        render_alerts(\n","            alerts_df,\n","            \"id\",\n","            \"time_center\",\n","            \"severity\",\n","            \"Alerts and suggested actions ‚Äì recent anomalous handovers\",\n","            \"handover\",\n","        )\n","        st.markdown(\n","            \"- Check whether the same customer or route is affected repeatedly.\\\\n\"\n","            \"- Inspect handover timing relative to satellite motion and beam footprints.\\\\n\"\n","            \"- Consider adjusting hysteresis or thresholds for problem beams.\"\n","        )\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Space Weather helpers\n","# ------------------------------\n","\n","def fetch_live_kp_index():\n","    if st.session_state.get(\"disable_live_kp\", False):\n","        return None, None\n","    try:\n","        url = \"https://services.swpc.noaa.gov/products/noaa-planetary-k-index.json\"\n","        resp = requests.get(url, timeout=5, headers={\"User-Agent\": \"ses-thesis-dashboard/1.0\"})\n","        resp.raise_for_status()\n","        data = resp.json()\n","        if not data or len(data) < 2:\n","            return None, None\n","        last_row = data[-1]\n","        ts_str = str(last_row[0])\n","        kp_raw = last_row[1]\n","        kp = float(kp_raw)\n","        return kp, ts_str\n","    except Exception:\n","        return None, None\n","\n","# ------------------------------\n","# Space Weather page\n","# ------------------------------\n","\n","def page_space_weather():\n","    render_academic_banner()\n","    st.title(tr(\"Space Weather\"))\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\"### What this use case monitors\")\n","    st.markdown(\n","        \"Space weather indices such as Kp capture geomagnetic activity. \"\n","        \"This prototype links those indices with thruster temperature and attitude \"\n","        \"error during station keeping and unload maneuvers, to flag windows where \"\n","        \"maneuver risk may be elevated.\"\n","    )\n","\n","    st.markdown(\"### Why this matters for operators\")\n","    st.markdown(\n","        \"- During strong geomagnetic storms the environment around the spacecraft changes.\\\\n\"\n","        \"- Maneuvers executed in those periods may have higher fuel usage or tighter thermal constraints.\\\\n\"\n","        \"- A simple risk indicator helps flight dynamics teams choose safer windows.\"\n","    )\n","\n","    col_main, col_side = st.columns([2, 1])\n","\n","    with col_main:\n","        st.markdown(\"### Feature importance over time for Space Weather maneuver model (SHAP values)\")\n","        shap_df, feat_names, time_labels = load_shap_matrix(\n","            \"artifacts_spaceweather/spaceweather_risky_shap_values.csv\"\n","        )\n","        if shap_df is not None:\n","            fig_shap = px.imshow(\n","                shap_df,\n","                x=time_labels,\n","                y=feat_names,\n","                aspect=\"auto\",\n","                color_continuous_scale=\"RdBu\",\n","                origin=\"lower\",\n","                labels={\"x\": \"maneuver index / time\", \"y\": \"feature\", \"color\": \"SHAP value\"},\n","                title=\"Space Weather ‚Äì SHAP heatmap for top risky maneuvers\",\n","            )\n","            fig_shap = add_shap_hover(\n","                fig_shap,\n","                x_label=\"maneuver index\",\n","                y_label=\"feature\",\n","                context_note=\"Per Franco de la Pe√±a et al. (2025) on manoeuvre risk and space weather.\",\n","            )\n","            st.plotly_chart(fig_shap, use_container_width=True)\n","        else:\n","            event_img = load_image_path(\"artifacts_spaceweather/spaceweather_risky_heatmap.png\")\n","            cont_img = load_image_path(\"artifacts_spaceweather/spaceweather_continuous_heatmap.png\")\n","            if event_img:\n","                st.image(event_img, caption=\"Space Weather ‚Äì SHAP heatmap for top risky maneuvers\", use_container_width=True)\n","            if cont_img:\n","                st.image(cont_img, caption=\"Space Weather ‚Äì continuous SHAP importance over time\", use_container_width=True)\n","\n","        with st.expander(\"Learn more about how to read this SHAP heatmap\"):\n","            st.markdown(\n","                \"- Top rows correspond to thruster temperature and attitude error statistics; \"\n","                \"lower rows show Kp history and storm flags.\\\\n\"\n","                \"- Warm cells mean those values pushed the classifier towards the risky class.\\\\n\"\n","                \"- Blocks of warm Kp features across multiple maneuvers highlight prolonged disturbed periods.\"\n","            )\n","\n","        lit_expander(\"spaceweather\")\n","\n","    with col_side:\n","        maneuvers = load_csv(\"ses_spaceweather_dataset.csv\", parse_dates=[\"time\"])\n","        alerts_df = None\n","        if maneuvers is not None and \"risk_score\" in maneuvers.columns:\n","            maneuvers = maneuvers.sort_values(\"time\", ascending=False).head(50)\n","            maneuvers[\"time_center\"] = maneuvers[\"time\"]\n","            maneuvers[\"severity\"] = np.where(maneuvers[\"risk_score\"] > 0.6, \"high\", \"medium\")\n","            maneuvers[\"id\"] = maneuvers[\"maneuver_type\"]\n","            maneuvers = apply_time_filter(maneuvers, \"time_center\")\n","            if not maneuvers.empty:\n","                alerts_df = maneuvers[[\"id\", \"time_center\", \"severity\"]]\n","        render_alerts(\n","            alerts_df,\n","            \"id\",\n","            \"time_center\",\n","            \"severity\",\n","            \"Upcoming or recent risky maneuvers\",\n","            \"spaceweather\",\n","        )\n","        st.markdown(\n","            \"- Avoid planning non-urgent maneuvers during long periods with high Kp.\\\\n\"\n","            \"- Coordinate with ground segment teams when storm intensity is high, as link margins may also be affected.\"\n","        )\n","\n","    st.markdown(\"---\")\n","    st.markdown(tr(\"Current space weather (live NOAA Kp index)\"))\n","\n","    kp_val, kp_ts = fetch_live_kp_index()\n","    if kp_val is None:\n","        st.info(\n","            \"In this offline thesis environment the live Kp index call may be blocked. \"\n","            \"In a production deployment this panel would query NOAA's public API.\"\n","        )\n","    else:\n","        st.metric(\"Latest planetary K-index\", f\"{kp_val:.1f}\")\n","        if kp_ts:\n","            st.caption(\"As of: \" + kp_ts)\n","        st.caption(\n","            \"Values above ~5 indicate geomagnetic storm levels that may affect \"\n","            \"satellite operations and link margins.\"\n","        )\n","\n","    st.markdown(tr(\"Earth in real time (NOAA) ‚Äì external view\"))\n","    st.info(\n","        \"For a full interactive view of Earth's current cloud cover and weather, \"\n","        \"open the NOAA 'Earth in Real Time' map in a new browser tab.\"\n","    )\n","    st.link_button(tr(\"Open NOAA Earth in Real Time\"), \"https://www.nesdis.noaa.gov/imagery/interactive-maps/earth-real-time\")\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Capacity page (synthetic demo with alerts)\n","# ------------------------------\n","\n","def synth_capacity_demo():\n","    idx = pd.date_range(\"2021-10-25\", \"2021-11-01\", freq=\"H\")\n","    beams = [\"Beam-A\", \"Beam-B\", \"Beam-C\"]\n","    rows = []\n","    rng = np.random.default_rng(42)\n","    for b in beams:\n","        base_cap = rng.uniform(200, 260)\n","        for t in idx:\n","            demand = base_cap * rng.uniform(0.4, 1.2)\n","            cap = base_cap * rng.uniform(0.9, 1.1)\n","            rows.append({\"time\": t, \"beam\": b, \"capacity\": cap, \"demand\": demand})\n","    df = pd.DataFrame(rows)\n","    df[\"headroom\"] = df[\"capacity\"] - df[\"demand\"]\n","    df[\"risk_index\"] = 1.0 - (df[\"headroom\"] / df[\"capacity\"]).clip(0, 1)\n","    return df\n","\n","def page_capacity():\n","    render_academic_banner()\n","    st.title(tr(\"Risk-aware Capacity Advisor\"))\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\n","        \"This page illustrates a forward-looking risk score per beam or region. \"\n","        \"The score combines demand forecast (synthetic in this prototype), available \"\n","        \"capacity and historical utilisation.\"\n","    )\n","    st.caption(\"Synthetic data; real SES metrics are discussed in the thesis evaluation chapter.\")\n","    lit_expander(\"capacity\")\n","\n","    df = load_csv(\"artifacts_capacity/capacity_risk_demo.csv\", parse_dates=[\"time\"])\n","    if df is None:\n","        df = synth_capacity_demo()\n","\n","    df = apply_time_filter(df, \"time\")\n","\n","    beam_options = [\"ALL\"] + sorted(df[\"beam\"].unique().tolist())\n","    beam = st.selectbox(\"Beam or region\", beam_options)\n","\n","    horizon_label = st.selectbox(\"Forecast horizon\", [\"Next 6 hours\", \"Next 24 hours\", \"Next 72 hours\"])\n","    if \"6\" in horizon_label:\n","        horizon_hours = 6\n","    elif \"24\" in horizon_label:\n","        horizon_hours = 24\n","    else:\n","        horizon_hours = 72\n","\n","    latest_time = df[\"time\"].max()\n","    window_start = latest_time - pd.Timedelta(hours=horizon_hours)\n","    df_win = df[df[\"time\"].between(window_start, latest_time)].copy()\n","    if beam != \"ALL\":\n","        df_win = df_win[df_win[\"beam\"] == beam]\n","\n","    if df_win.empty:\n","        st.info(\"No capacity data in this filtered window.\")\n","        return\n","\n","    st.markdown(\"#### Capacity, demand and risk over selected horizon\")\n","    fig = px.line(\n","        df_win,\n","        x=\"time\",\n","        y=[\"capacity\", \"demand\", \"risk_index\"],\n","        labels={\"value\": \"Mbps / risk\", \"variable\": \"Series\"},\n","    )\n","    fig.update_layout(\n","        margin=dict(l=0, r=0, t=40, b=0),\n","        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02),\n","    )\n","    st.plotly_chart(fig, use_container_width=True)\n","\n","    st.markdown(\n","        \"Risk index values close to 1.0 indicate little spare headroom between demand \"\n","        \"and capacity. In a production system this would be driven by a demand forecast \"\n","        \"and spectrum-plan optimisation model.\"\n","    )\n","\n","    st.markdown(\"#### Simple feature importance for risk_index (synthetic)\")\n","    if all(c in df_win.columns for c in [\"headroom\"]):\n","        demo_imp = pd.DataFrame(\n","            {\n","                \"driver\": [\"Demand pressure\", \"Headroom\", \"Capacity variability\"],\n","                \"avg_risk\": [0.85, 0.65, 0.55],\n","            }\n","        )\n","        fig_imp = px.bar(\n","            demo_imp,\n","            x=\"driver\",\n","            y=\"avg_risk\",\n","            title=\"Average contribution of drivers to risk_index (demo)\",\n","        )\n","        fig_imp.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig_imp, use_container_width=True)\n","    else:\n","        st.caption(\n","            \"In a full implementation this section would show SHAP-based feature \"\n","            \"importance for risk_index per beam.\"\n","        )\n","\n","    st.markdown(\"#### Alerts and suggested actions\")\n","    df_last = df_win.sort_values(\"time\", ascending=False).head(20)\n","    df_last[\"severity\"] = np.where(df_last[\"risk_index\"] > 0.8, \"high\", \"medium\")\n","    df_last[\"id\"] = df_last[\"beam\"]\n","    df_last[\"time_center\"] = df_last[\"time\"]\n","    alerts_df = df_last[[\"id\", \"time_center\", \"severity\"]]\n","    render_alerts(\n","        alerts_df,\n","        \"id\",\n","        \"time_center\",\n","        \"severity\",\n","        \"Beams with highest short-term capacity risk\",\n","        \"capacity\",\n","    )\n","    st.markdown(\n","        \"- For beams with persistent high risk, review traffic mix and consider temporary capacity increase.\\\\n\"\n","        \"- Coordinate with planning teams if several adjacent beams show rising risk.\\\\n\"\n","        \"- High sustained risk on busy beams could translate to roughly 5‚Äì10k EUR per hour \"\n","        \"in potential SLA penalties if left unmitigated.\"\n","    )\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Stress index page\n","# ------------------------------\n","\n","def synth_stress_demo():\n","    idx = pd.date_range(\"2021-10-25\", \"2021-11-01\", freq=\"H\")\n","    rng = np.random.default_rng(123)\n","    df = pd.DataFrame({\"time\": idx})\n","    df[\"signal_loss_risk\"] = rng.uniform(0, 0.6, len(idx))\n","    df[\"jamming_risk\"] = rng.uniform(0, 0.5, len(idx))\n","    df[\"sla_risk\"] = rng.uniform(0, 0.7, len(idx))\n","    df[\"capacity_risk\"] = rng.uniform(0, 0.8, len(idx))\n","    df[\"stress_index\"] = df[\n","        [\"signal_loss_risk\", \"jamming_risk\", \"sla_risk\", \"capacity_risk\"]\n","    ].max(axis=1)\n","    return df\n","\n","def page_stress():\n","    render_academic_banner()\n","    st.title(tr(\"Stress Index & Joint Risk Radar\"))\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\n","        \"The stress index combines signals from several models into one compact view. \"\n","        \"Instead of four or five separate alert streams, the NOC gets an at-a-glance \"\n","        \"indicator of how stressed the network is over time on each satellite. \"\n","        \"This design is proposed by Sabino et al. (2025) and inspired by \"\n","        \"system-level explanation work from Iino et al. (2024).\"\n","    )\n","    lit_expander(\"stress\")\n","\n","    df = load_csv(\"artifacts_stress/stress_index_demo.csv\", parse_dates=[\"time\"])\n","    if df is None:\n","        df = synth_stress_demo()\n","\n","    df = apply_time_filter(df, \"time\")\n","\n","    st.markdown(\"#### Stress index over time\")\n","    fig = px.line(\n","        df,\n","        x=\"time\",\n","        y=\"stress_index\",\n","        title=\"Combined stress index (demo)\",\n","    )\n","    fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","    st.plotly_chart(fig, use_container_width=True)\n","\n","    st.markdown(\n","        \"Peaks in the stress index correspond to periods where at least one underlying \"\n","        \"model showed elevated risk. Use this page as a radar: when stress spikes, \"\n","        \"check the table below to see which driver dominates and then drill down into \"\n","        \"the relevant use-case page from the left-hand menu.\"\n","    )\n","\n","    st.markdown(\"#### Radar-style breakdown of dominant drivers\")\n","    latest_slice = df.tail(48).copy()\n","    rows = []\n","    for _, r in latest_slice.iterrows():\n","        drivers = {\n","            \"Signal loss\": r.get(\"signal_loss_risk\", 0.0),\n","            \"Jamming\": r.get(\"jamming_risk\", 0.0),\n","            \"SLA\": r.get(\"sla_risk\", 0.0),\n","            \"Capacity\": r.get(\"capacity_risk\", 0.0),\n","        }\n","        dominant = max(drivers, key=drivers.get)\n","        rows.append(\n","            {\n","                \"time\": r[\"time\"],\n","                \"stress_index\": r[\"stress_index\"],\n","                \"dominant_driver\": dominant,\n","            }\n","        )\n","    df_dom = pd.DataFrame(rows)\n","    st.dataframe(df_dom.tail(12))\n","\n","    st.caption(\n","        \"Use the dominant_driver column as a pointer: for example, if several rows show \"\n","        \"Jamming, open the 'Jamming / Interference' page and inspect SHAP heatmaps \"\n","        \"and alerts for that period.\"\n","    )\n","\n","    st.markdown(\"#### Polar chart of average risk contributions (demo)\")\n","    avg_vals = {\n","        \"Signal loss\": df[\"signal_loss_risk\"].mean() if \"signal_loss_risk\" in df.columns else 0.0,\n","        \"Jamming\": df[\"jamming_risk\"].mean() if \"jamming_risk\" in df.columns else 0.0,\n","        \"SLA\": df[\"sla_risk\"].mean() if \"sla_risk\" in df.columns else 0.0,\n","        \"Capacity\": df[\"capacity_risk\"].mean() if \"capacity_risk\" in df.columns else 0.0,\n","    }\n","    polar_df = pd.DataFrame(\n","        {\n","            \"driver\": list(avg_vals.keys()),\n","            \"avg_risk\": list(avg_vals.values()),\n","        }\n","    )\n","    polar_df = pd.concat([polar_df, polar_df.iloc[[0]]], ignore_index=True)\n","    fig_polar = px.line_polar(\n","        polar_df,\n","        r=\"avg_risk\",\n","        theta=\"driver\",\n","        line_close=True,\n","        title=\"Average contribution of each driver to stress (demo)\",\n","    )\n","    fig_polar.update_traces(fill=\"toself\")\n","    fig_polar.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","    st.plotly_chart(fig_polar, use_container_width=True)\n","\n","    st.markdown(\"#### Alerts and suggested actions\")\n","    df_last = df.sort_values(\"time\", ascending=False).head(10)\n","    df_last[\"severity\"] = np.where(df_last[\"stress_index\"] > 0.8, \"high\", \"medium\")\n","    df_last[\"id\"] = \"SAT net\"\n","    df_last[\"time_center\"] = df_last[\"time\"]\n","    alerts_df = df_last[[\"id\", \"time_center\", \"severity\"]]\n","    render_alerts(\n","        alerts_df,\n","        \"id\",\n","        \"time_center\",\n","        \"severity\",\n","        \"Most stressed recent periods\",\n","        \"stress\",\n","    )\n","    st.markdown(\n","        \"- Use this page as a radar: when stress spikes, consult the dominant-driver table \"\n","        \"and open the corresponding use case page.\\\\n\"\n","        \"- Periods with sustained stress above ~0.8 across key beams could correspond to \"\n","        \"significant operational risk, potentially translating into tens of thousands of \"\n","        \"EUR per day if left unmanaged.\"\n","    )\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Alert Analytics (Thesis Mode) -- OLD\n","# ------------------------------\n","\n","def page_alert_analytics_OLD():\n","    render_academic_banner()\n","    st.title(\"Alert Analytics (Thesis Mode)\")\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\n","        \"This page aggregates alerts from all use cases (including their severities and \"\n","        \"acknowledgements). In the thesis this supports Phase 4 evaluation: measuring alert \"\n","        \"volume, severity mix and acknowledgement behaviour as a proxy for alert fatigue \"\n","        \"and operational usefulness.\"\n","    )\n","    lit_expander(\"alerts\")\n","\n","    if not ALERT_HISTORY_CSV.exists():\n","        st.info(\"No alert history CSV found yet. Interact with alerts in other pages to generate data.\")\n","        render_thesis_footer()\n","        return\n","\n","    alerts = pd.read_csv(ALERT_HISTORY_CSV)\n","    # ---- Compute time-to-ack (seconds) ----\n","    #if \"time_center\" in alerts.columns and \"acked_at_utc\" in alerts.columns:\n","    #    alerts[\"time_center\"] = pd.to_datetime(alerts[\"time_center\"], errors=\"coerce\")\n","    #    alerts[\"acked_at_utc\"] = pd.to_datetime(alerts[\"acked_at_utc\"], errors=\"coerce\")\n","    #    alerts[\"time_to_ack_s\"] = (\n","    #        alerts[\"acked_at_utc\"] - alerts[\"time_center\"]\n","    #    ).dt.total_seconds()\n","    #else:\n","    #    alerts[\"time_to_ack_s\"] = np.nan\n","\n","    if \"time_center\" in alerts.columns:\n","        alerts[\"time_center\"] = pd.to_datetime(alerts[\"time_center\"], errors=\"coerce\", utc=True)\n","\n","    if \"acked_at_utc\" in alerts.columns:\n","        alerts[\"acked_at_utc\"] = pd.to_datetime(alerts[\"acked_at_utc\"], errors=\"coerce\", utc=True)\n","\n","    # Compute time-to-ack in seconds (safe)\n","    if \"time_center\" in alerts.columns and \"acked_at_utc\" in alerts.columns:\n","        alerts[\"time_to_ack_s\"] = (alerts[\"acked_at_utc\"] - alerts[\"time_center\"]).dt.total_seconds()\n","    else:\n","        alerts[\"time_to_ack_s\"] = np.nan\n","\n","\n","\n","    #-----\n","    #if \"time_center\" in alerts.columns:\n","    #    alerts[\"time_center\"] = pd.to_datetime(alerts[\"time_center\"], errors=\"coerce\")\n","    #if \"acked_at_utc\" in alerts.columns:\n","    #    alerts[\"acked_at_utc\"] = pd.to_datetime(alerts[\"acked_at_utc\"], errors=\"coerce\")\n","\n","    st.markdown(\"### Latest alerts (combined)\")\n","    st.dataframe(alerts.sort_values(\"acked_at_utc\", ascending=False).head(25))\n","\n","    st.markdown(\"### Alert severity mix\")\n","    sev_counts = alerts[\"severity\"].value_counts().reset_index()\n","    sev_counts.columns = [\"severity\", \"count\"]\n","    if not sev_counts.empty:\n","        fig = px.bar(sev_counts, x=\"severity\", y=\"count\", title=\"Alert counts by severity\")\n","        fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig, use_container_width=True)\n","\n","    st.markdown(\"### Alerts over time (hourly)\")\n","    if \"time_center\" in alerts.columns:\n","        alerts_valid = alerts.dropna(subset=[\"time_center\"]).copy()\n","        alerts_valid[\"time_hour\"] = alerts_valid[\"time_center\"].dt.floor(\"H\")\n","        by_hour = alerts_valid.groupby(\"time_hour\").size().reset_index(name=\"alert_count\")\n","        if not by_hour.empty:\n","            fig = px.line(by_hour, x=\"time_hour\", y=\"alert_count\", title=\"Alert volume per hour\")\n","            fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","            st.plotly_chart(fig, use_container_width=True)\n","\n","\n","\n","    acked = alerts.dropna(subset=[\"acked_at_utc\"])\n","    ack_rate = len(acked) / max(len(alerts), 1)\n","\n","   #median_tta = (\n","   #     acked[\"time_to_ack_s\"].median()\n","   #     if \"time_to_ack_s\" in acked.columns and not acked.empty\n","   #     else np.nan\n","   #)\n","\n","    median_tta = (\n","        acked[\"time_to_ack_s\"].median()\n","        if \"time_to_ack_s\" in acked.columns and not acked.empty\n","        else None\n","    )\n","\n","    c1, c2, c3, c4 = st.columns(4)\n","    c1.metric(\"Total alerts\", len(alerts))\n","    c2.metric(\"Acknowledged alerts\", len(acked))\n","    c3.metric(\"Acknowledgement rate\", f\"{ack_rate*100:.1f}%\")\n","    #c4.metric(\n","    #    \"Median time-to-ack (s)\",\n","    #    f\"{median_tta:.0f}\" if not np.isnan(median_tta) else \"N/A\"\n","    #)\n","    c4.metric(\n","        \"Median time-to-ack (s)\",\n","        f\"{int(round(median_tta))} s\" if median_tta is not None and not np.isnan(median_tta) else \"N/A\"\n","    )\n","\n","    st.caption(\n","        \"Time-to-ack is computed as the elapsed time between alert creation \"\n","        \"and operator acknowledgement. Lower values indicate clearer, more \"\n","        \"actionable alerts and reduced operational friction.\"\n","    )\n","\n","\n","    st.markdown(\"### Before / after threshold comparison\")\n","\n","    if \"threshold_version\" not in alerts.columns:\n","        st.info(\n","            \"No threshold version tags found. \"\n","            \"Enable threshold tagging in alert generation to compare regimes.\"\n","        )\n","    else:\n","        cmp = alerts.groupby(\"threshold_version\").agg(\n","            total_alerts=(\"alert_key\", \"count\"),\n","            acknowledged=(\"acked_at_utc\", lambda x: x.notna().sum()),\n","            median_time_to_ack_s=(\"time_to_ack_s\", \"median\"),\n","        ).reset_index()\n","\n","        cmp[\"ack_rate\"] = cmp[\"acknowledged\"] / cmp[\"total_alerts\"]\n","\n","        st.dataframe(\n","            cmp.style.format(\n","                {\n","                    \"ack_rate\": \"{:.1%}\",\n","                    \"median_time_to_ack_s\": \"{:.0f}\",\n","                }\n","            ),\n","            use_container_width=True\n","        )\n","\n","        fig_vol = px.bar(\n","            cmp,\n","            x=\"threshold_version\",\n","            y=\"total_alerts\",\n","            title=\"Alert volume by threshold regime\"\n","        )\n","        st.plotly_chart(fig_vol, use_container_width=True)\n","\n","        fig_ack = px.bar(\n","            cmp,\n","            x=\"threshold_version\",\n","            y=\"ack_rate\",\n","            range_y=[0, 1],\n","            title=\"Acknowledgement rate by threshold regime\"\n","        )\n","        st.plotly_chart(fig_ack, use_container_width=True)\n","\n","        fig_tta = px.bar(\n","            cmp,\n","            x=\"threshold_version\",\n","            y=\"median_time_to_ack_s\",\n","            title=\"Median time-to-ack by threshold regime (seconds)\"\n","        )\n","        st.plotly_chart(fig_tta, use_container_width=True)\n","\n","    st.caption(\n","        \"This comparison demonstrates the operational trade-off between alert volume \"\n","        \"and actionability. Precision-first settings typically reduce alert load while \"\n","        \"improving acknowledgement rates and response times.\"\n","    )\n","\n","\n","\n","\n","    st.download_button(\"Download alert history CSV\", data=alerts.to_csv(index=False), file_name=\"alert_history.csv\")\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Alert Analytics (Thesis Mode)\n","# ------------------------------\n","\n","def page_alert_analytics():\n","    render_academic_banner()\n","    st.title(\"Alert Analytics (Thesis Mode)\")\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\n","        \"This page aggregates alerts from all use cases (including their severities and \"\n","        \"acknowledgements). In the thesis this supports Phase 4 evaluation: measuring alert \"\n","        \"volume, severity mix and acknowledgement behaviour as a proxy for alert fatigue \"\n","        \"and operational usefulness.\"\n","    )\n","    lit_expander(\"alerts\")\n","\n","    if not ALERT_HISTORY_CSV.exists():\n","        st.info(\"No alert history CSV found yet. Interact with alerts in other pages to generate data.\")\n","        render_thesis_footer()\n","        return\n","\n","    alerts = pd.read_csv(ALERT_HISTORY_CSV)\n","\n","    # --- Parse timestamps consistently as tz-aware UTC ---\n","    if \"time_center\" in alerts.columns:\n","        alerts[\"time_center\"] = pd.to_datetime(alerts[\"time_center\"], errors=\"coerce\", utc=True)\n","    else:\n","        alerts[\"time_center\"] = pd.NaT\n","\n","    if \"acked_at_utc\" in alerts.columns:\n","        alerts[\"acked_at_utc\"] = pd.to_datetime(alerts[\"acked_at_utc\"], errors=\"coerce\", utc=True)\n","    else:\n","        alerts[\"acked_at_utc\"] = pd.NaT\n","\n","    # --- Compute time-to-ack (seconds) safely ---\n","    alerts[\"time_to_ack_s\"] = (alerts[\"acked_at_utc\"] - alerts[\"time_center\"]).dt.total_seconds()\n","\n","    # Remove pathological negatives (can happen if clocks/serialization are inconsistent)\n","    alerts.loc[alerts[\"time_to_ack_s\"] < 0, \"time_to_ack_s\"] = np.nan\n","\n","    # Acknowledged subset\n","    acked = alerts.dropna(subset=[\"acked_at_utc\"]).copy()\n","    ack_rate = len(acked) / max(len(alerts), 1)\n","\n","    # Median TTA\n","    median_tta = (\n","        float(acked[\"time_to_ack_s\"].median())\n","        if \"time_to_ack_s\" in acked.columns and not acked.empty\n","        else None\n","    )\n","\n","    # Median TTA CI (bootstrap)\n","    median_ci = None\n","    if not acked.empty and \"time_to_ack_s\" in acked.columns:\n","        median_ci = bootstrap_median_ci(acked[\"time_to_ack_s\"], n_boot=2000, ci=0.95, seed=42)\n","\n","    st.markdown(\"### Latest alerts (combined)\")\n","    st.dataframe(alerts.sort_values(\"acked_at_utc\", ascending=False).head(25))\n","\n","    st.markdown(\"### Alert severity mix\")\n","    if \"severity\" in alerts.columns:\n","        sev_counts = alerts[\"severity\"].value_counts().reset_index()\n","        sev_counts.columns = [\"severity\", \"count\"]\n","        if not sev_counts.empty:\n","            fig = px.bar(sev_counts, x=\"severity\", y=\"count\", title=\"Alert counts by severity\")\n","            fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","            st.plotly_chart(fig, use_container_width=True)\n","    else:\n","        st.info(\"No severity column found in alert history CSV.\")\n","\n","    st.markdown(\"### Alerts over time (hourly)\")\n","    alerts_valid = alerts.dropna(subset=[\"time_center\"]).copy()\n","    if not alerts_valid.empty:\n","        alerts_valid[\"time_hour\"] = alerts_valid[\"time_center\"].dt.floor(\"H\")\n","        by_hour = alerts_valid.groupby(\"time_hour\").size().reset_index(name=\"alert_count\")\n","        if not by_hour.empty:\n","            fig = px.line(by_hour, x=\"time_hour\", y=\"alert_count\", title=\"Alert volume per hour\")\n","            fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","            st.plotly_chart(fig, use_container_width=True)\n","\n","    st.markdown(\"### Acknowledgement behaviour\")\n","    c1, c2, c3, c4 = st.columns(4)\n","    c1.metric(\"Total alerts\", len(alerts))\n","    c2.metric(\"Acknowledged alerts\", len(acked))\n","    c3.metric(\"Acknowledgement rate\", f\"{ack_rate*100:.1f}%\")\n","    c4.metric(\n","        \"Median time-to-ack\",\n","        f\"{int(round(median_tta))} s\" if median_tta is not None and not np.isnan(median_tta) else \"N/A\"\n","    )\n","\n","    if median_ci is not None:\n","        lo, hi = median_ci\n","        st.caption(f\"95% bootstrap CI for median time-to-ack: {int(round(lo))} s to {int(round(hi))} s\")\n","    else:\n","        st.caption(\"95% bootstrap CI not shown (insufficient acknowledged alerts).\")\n","\n","    st.caption(\n","        \"Time-to-ack is computed as the elapsed time between alert creation \"\n","        \"and operator acknowledgement. Lower values indicate clearer, more \"\n","        \"actionable alerts and reduced operational friction.\"\n","    )\n","\n","    # -----------------------------\n","    # Box plot: time-to-ack by severity\n","    # -----------------------------\n","    st.markdown(\"### Time-to-ack by severity (box plot)\")\n","\n","    acked_valid = alerts.dropna(subset=[\"acked_at_utc\", \"time_center\", \"time_to_ack_s\"]).copy()\n","\n","    # Optional cap to keep plot readable; adjust as needed\n","    acked_valid = acked_valid[(acked_valid[\"time_to_ack_s\"] >= 0) & (acked_valid[\"time_to_ack_s\"] <= 7 * 24 * 3600)]\n","\n","    if acked_valid.empty or \"severity\" not in acked_valid.columns:\n","        st.info(\"Not enough acknowledged alerts with severity to plot time-to-ack distribution.\")\n","    else:\n","        acked_valid[\"severity\"] = acked_valid[\"severity\"].astype(str).str.lower().str.strip()\n","        fig_box = px.box(\n","            acked_valid,\n","            x=\"severity\",\n","            y=\"time_to_ack_s\",\n","            points=\"all\",\n","            title=\"Time-to-ack distribution by severity (seconds)\",\n","            labels={\"severity\": \"Severity\", \"time_to_ack_s\": \"Time-to-ack (s)\"},\n","        )\n","        fig_box.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig_box, use_container_width=True)\n","        st.caption(\n","            \"Interpretation: Lower medians and tighter spreads indicate faster, more actionable alerts. \"\n","            \"In Phase 4 this supports the alert-fatigue / actionability analysis.\"\n","        )\n","\n","    # -----------------------------\n","    # Before / after threshold comparison\n","    # -----------------------------\n","    st.markdown(\"### Before / after threshold comparison\")\n","\n","    if \"threshold_version\" not in alerts.columns:\n","        st.info(\n","            \"No threshold version tags found. \"\n","            \"Enable threshold tagging in alert generation to compare regimes.\"\n","        )\n","    else:\n","        # Use a robust count column even if alert_key doesn't exist\n","        count_col = \"alert_key\" if \"alert_key\" in alerts.columns else \"alert_id\"\n","        if count_col not in alerts.columns:\n","            # fallback: count rows\n","            cmp = alerts.groupby(\"threshold_version\").size().reset_index(name=\"total_alerts\")\n","            cmp[\"acknowledged\"] = alerts.groupby(\"threshold_version\")[\"acked_at_utc\"].apply(lambda x: x.notna().sum()).values\n","            cmp[\"median_time_to_ack_s\"] = alerts.groupby(\"threshold_version\")[\"time_to_ack_s\"].median().values\n","        else:\n","            cmp = alerts.groupby(\"threshold_version\").agg(\n","                total_alerts=(count_col, \"count\"),\n","                acknowledged=(\"acked_at_utc\", lambda x: x.notna().sum()),\n","                median_time_to_ack_s=(\"time_to_ack_s\", \"median\"),\n","            ).reset_index()\n","\n","        cmp[\"ack_rate\"] = cmp[\"acknowledged\"] / cmp[\"total_alerts\"].replace(0, np.nan)\n","\n","        st.dataframe(\n","            cmp.style.format(\n","                {\n","                    \"ack_rate\": \"{:.1%}\",\n","                    \"median_time_to_ack_s\": \"{:.0f}\",\n","                }\n","            ),\n","            use_container_width=True\n","        )\n","\n","        fig_vol = px.bar(cmp, x=\"threshold_version\", y=\"total_alerts\", title=\"Alert volume by threshold regime\")\n","        fig_vol.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig_vol, use_container_width=True)\n","\n","        fig_ack = px.bar(cmp, x=\"threshold_version\", y=\"ack_rate\", range_y=[0, 1], title=\"Acknowledgement rate by threshold regime\")\n","        fig_ack.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig_ack, use_container_width=True)\n","\n","        fig_tta = px.bar(cmp, x=\"threshold_version\", y=\"median_time_to_ack_s\", title=\"Median time-to-ack by threshold regime (seconds)\")\n","        fig_tta.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig_tta, use_container_width=True)\n","\n","    st.caption(\n","        \"This comparison demonstrates the operational trade-off between alert volume \"\n","        \"and actionability. Precision-first settings typically reduce alert load while \"\n","        \"improving acknowledgement rates and response times.\"\n","    )\n","\n","    st.download_button(\"Download alert history CSV\", data=alerts.to_csv(index=False), file_name=\"alert_history.csv\")\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Feedback Analytics (Thesis Mode)\n","# ------------------------------\n","\n","def page_feedback_analytics():\n","    render_academic_banner()\n","    st.title(\"Feedback Analytics (Thesis Mode)\")\n","    render_thesis_header()\n","\n","    st.markdown(\"---\")\n","    st.markdown(\n","        \"This page summarises the operator / stakeholder feedback collected via the dashboard. \"\n","        \"It supports Phase 4 evaluation by providing quick views of sentiment, usability scores \"\n","        \"and themes related to SHAP explanations and trust.\"\n","    )\n","    lit_expander(\"feedback\")\n","\n","    if not FEEDBACK_CSV.exists():\n","        st.info(\"No feedback CSV found yet. Provide feedback on the Overview page to generate data.\")\n","        render_thesis_footer()\n","        return\n","\n","    fb = pd.read_csv(FEEDBACK_CSV)\n","\n","    st.markdown(\"### 1. Role mix\")\n","    if \"role\" in fb.columns:\n","        role_counts = fb[\"role\"].value_counts().reset_index()\n","        role_counts.columns = [\"role\", \"count\"]\n","        fig = px.bar(role_counts, x=\"role\", y=\"count\", title=\"Feedback count by role\")\n","        fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig, use_container_width=True)\n","\n","    st.markdown(\"### 2. Impact estimates\")\n","    if \"impact_estimate\" in fb.columns:\n","        impact_counts = fb[\"impact_estimate\"].value_counts().reset_index()\n","        impact_counts.columns = [\"impact_estimate\", \"count\"]\n","        fig = px.bar(impact_counts, x=\"impact_estimate\", y=\"count\", title=\"Perceived impact of deployment\")\n","        fig.update_layout(xaxis_tickangle=-45, margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig, use_container_width=True)\n","\n","    st.markdown(\"### 3. Usability scores (1‚Äì5)\")\n","    ux_cols = [c for c in fb.columns if c.startswith(\"ux_\")]\n","    if ux_cols:\n","        ux_means = fb[ux_cols].mean().reset_index()\n","        ux_means.columns = [\"dimension\", \"mean_score\"]\n","        fig = px.bar(ux_means, x=\"dimension\", y=\"mean_score\", range_y=[1, 5], title=\"Average UX scores\")\n","        fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig, use_container_width=True)\n","    else:\n","        st.info(\"No quantitative UX scores found in the CSV (columns ux_*).\")\n","\n","    st.markdown(\"### 4. Keyword and sentiment analysis of free-text feedback\")\n","\n","    explanation_text = textwrap.dedent(\n","        \"\"\"\n","        Sentiment polarity is computed using TextBlob when available:\n","        values range from -1 (very negative) through 0 (neutral) to +1 (very positive).\n","        This is a lightweight proxy for how positively operators talk about the dashboard\n","        and explanations (Tjoa & Guan, 2020 highlight the importance of such signals).\n","        \"\"\"\n","    )\n","    st.caption(explanation_text)\n","\n","    fb[\"feedback\"] = fb.get(\"feedback\", \"\").fillna(\"\").astype(str)\n","    keyword_counts = {\n","        \"shap\": fb[\"feedback\"].str.contains(\"shap\", case=False).sum(),\n","        \"explain\": fb[\"feedback\"].str.contains(\"explain\", case=False).sum(),\n","        \"confusing\": fb[\"feedback\"].str.contains(\"confus\", case=False).sum(),\n","        \"useful\": fb[\"feedback\"].str.contains(\"useful\", case=False).sum(),\n","    }\n","\n","    sentiment_available = False\n","    try:\n","        from textblob import TextBlob  # type: ignore\n","        fb[\"sentiment_polarity\"] = fb[\"feedback\"].fillna(\"\").astype(str).apply(\n","            lambda x: TextBlob(x).sentiment.polarity\n","        )\n","        sentiment_available = True\n","    except Exception:\n","        fb[\"sentiment_polarity\"] = np.nan\n","        sentiment_available = False\n","\n","    # Compute keyword_counts with explicit int conversion\n","    keyword_counts = {\n","        \"shap\": int(fb[\"feedback\"].str.contains(\"shap\", case=False).sum()),\n","        \"explain\": int(fb[\"feedback\"].str.contains(\"explain\", case=False).sum()),\n","        \"confusing\": int(fb[\"feedback\"].str.contains(\"confus\", case=False).sum()),\n","        \"useful\": int(fb[\"feedback\"].str.contains(\"useful\", case=False).sum()),\n","    }\n","\n","    avg_polarity = None\n","    if sentiment_available and not fb.empty:\n","        m = fb[\"sentiment_polarity\"].mean()\n","        if pd.notna(m):\n","            avg_polarity = float(m)\n","\n","    with st.expander(\"Keyword and sentiment summary\", expanded=True):\n","        st.json(\n","            {\n","                \"keyword_counts\": keyword_counts,  # Now plain ints\n","                \"sentiment_available\": bool(sentiment_available),\n","                \"average_polarity\": avg_polarity,  # float or None\n","            }\n","        )\n","\n","\n","    # Build raw counts (these will be numpy.int64)\n","    keyword_counts_raw = {\n","        \"shap\": fb[\"feedback\"].str.contains(\"shap\", case=False).sum(),\n","        \"explain\": fb[\"feedback\"].str.contains(\"explain\", case=False).sum(),\n","        \"confusing\": fb[\"feedback\"].str.contains(\"confus\", case=False).sum(),\n","        \"useful\": fb[\"feedback\"].str.contains(\"useful\", case=False).sum(),\n","                         }\n","\n","    if sentiment_available:\n","        st.markdown(\"#### Sentiment polarity distribution\")\n","        fig_sent = px.histogram(\n","            fb,\n","            x=\"sentiment_polarity\",\n","            nbins=20,\n","            range_x=[-1, 1],\n","            title=\"Distribution of feedback sentiment (TextBlob polarity)\",\n","        )\n","        fig_sent.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n","        st.plotly_chart(fig_sent, use_container_width=True)\n","        st.markdown(\n","            \"Values near **+1** indicate very positive comments, values near **-1** \"\n","            \"indicate negative comments, and values around **0** are neutral.\"\n","        )\n","    else:\n","        st.info(\n","            \"TextBlob is not available in this environment, so a detailed sentiment \"\n","            \"distribution plot cannot be generated. The JSON summary above still captures \"\n","            \"basic keyword usage.\"\n","        )\n","\n","    st.markdown(\"### 5. Raw feedback (for thematic analysis)\")\n","    st.dataframe(fb)\n","\n","    st.download_button(\"Download feedback CSV\", data=fb.to_csv(index=False), file_name=\"feedback.csv\")\n","\n","    st.caption(\n","        \"These summaries are designed to be exported or transcribed into the thesis evaluation \"\n","        \"chapter to close the loop between the dashboard and the research questions.\"\n","    )\n","\n","    render_thesis_footer()\n","\n","# ------------------------------\n","# Router\n","# ------------------------------\n","\n","if view == tr(\"Overview\"):\n","    page_overview()\n","elif view == tr(\"Signal Loss\"):\n","    page_signal_loss()\n","elif view == tr(\"Jamming / Interference\"):\n","    page_jamming()\n","elif view == tr(\"SLA Breach\"):\n","    page_sla()\n","elif view == tr(\"Beam Handover\"):\n","    page_handover()\n","elif view == tr(\"Space Weather\"):\n","    page_space_weather()\n","elif view == tr(\"Risk-aware Capacity Advisor\"):\n","    page_capacity()\n","elif view == tr(\"Stress Index & Joint Risk Radar\"):\n","    page_stress()\n","elif view == tr(\"Alert Analytics (Thesis Mode)\"):\n","    page_alert_analytics()\n","elif view == tr(\"Feedback Analytics (Thesis Mode)\"):\n","    page_feedback_analytics()\n","'''\n","\n","app_code = textwrap.dedent(app_code_raw)\n","with open(os.path.join(DASHBOARD_DIR, \"app.py\"), \"w\") as f:\n","    f.write(app_code)\n","\n","print(\"Saved:\", os.path.join(DASHBOARD_DIR, \"app.py\"))\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9203,"status":"ok","timestamp":1766573493675,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"uWao10Ixetq5","outputId":"92dc0142-b530-46b7-f46a-0a873aa8cb13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting deep-translator\n","  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (4.13.5)\n","Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (2.32.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.8)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.15.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.11.12)\n","Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n","Installing collected packages: deep-translator\n","Successfully installed deep-translator-1.11.4\n","Streamlit version: 1.52.2\n"]}],"source":["# =======================================================\n","# Step 3 - Install streamlit and translator\n","# =======================================================\n","!pip install deep-translator\n","!pip install streamlit -q\n","!python -c \"import streamlit; print('Streamlit version:', streamlit.__version__)\"\n","!python -m streamlit run /content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard/app.py \\\n","    --server.port 8501 --server.address 0.0.0.0 &>/tmp/streamlit.log &\n","!tail -n 50 /tmp/streamlit.log"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6331,"status":"ok","timestamp":1766134073588,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"Ifu40S44eRk_","outputId":"55e6ff20-39fe-4d46-ab2e-ff74ef193a3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: deep-translator in /usr/local/lib/python3.12/dist-packages (1.11.4)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (4.13.5)\n","Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (2.32.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.8)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.15.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.11.12)\n"]}],"source":["!pip install deep-translator"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1321,"status":"ok","timestamp":1766573501681,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"b20wiIWUajwT","outputId":"09d89eaf-d990-480c-f7db-b872825f0285"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100 39.3M  100 39.3M    0     0  35.9M      0  0:00:01  0:00:01 --:--:-- 74.3M\n"]}],"source":["# =======================================================\n","# Step 4 - Install cloudfare\n","# =======================================================\n","# Download cloudflared binary\n","!curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared\n","!chmod +x cloudflared\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1766573506013,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"rlvUbAe1a2px"},"outputs":[],"source":["# =======================================================\n","# Step 5 - Run streamlit\n","# =======================================================\n","\n","# Kill any previously running Streamlit processes to ensure a clean restart\n","!pkill -f streamlit\n","\n","!python -m streamlit run /content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard/app.py \\\n","    --server.port 8501 --server.address 0.0.0.0 &>/tmp/streamlit.log &"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":959,"status":"ok","timestamp":1766573509911,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"aN2HueMza4-i","outputId":"3a2ec747-5ace-44f2-df75-aedaa6fedd89"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\n","\n","  You can now view your Streamlit app in your browser.\n","\n","  URL: http://0.0.0.0:8501\n","\n","root        1270 46.7  0.5 232564 70196 ?        S    10:51   0:01 python3 -m streamlit run /content/drive/MyDrive/Colab_Notebooks/Thesis-AI/phase3_ses/dashboard/app.py --server.port 8501 --server.address 0.0.0.0\n","root        1287  0.0  0.0   7372  3492 ?        S    10:51   0:00 /bin/bash -c ps aux | grep streamlit\n","root        1289  0.0  0.0   6480  2376 ?        S    10:51   0:00 grep streamlit\n"]}],"source":["!tail -n 50 /tmp/streamlit.log\n","\n","!ps aux | grep streamlit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBKwCG46a62q","outputId":"e92b19e5-b561-4a28-cff9-22354eaabfea"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[90m2025-12-24T10:51:53Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n","\u001b[90m2025-12-24T10:51:53Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m |  https://expo-cooking-adventure-also.trycloudflare.com                                     |\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 1adda9aa-4bc5-4264-9b2c-bbeddb201df0\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n","\u001b[90m2025-12-24T10:51:56Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n","2025/12/24 10:51:56 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n","\u001b[90m2025-12-24T10:51:57Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m636a676d-57c5-481a-9521-29acedec610b \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63 \u001b[36mlocation=\u001b[0msea07 \u001b[36mprotocol=\u001b[0mquic\n"]}],"source":["# =======================================================\n","# Step 6 - Launch cloudfare\n","# =======================================================\n","\n","!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":522,"status":"ok","timestamp":1764949306096,"user":{"displayName":"Amadiz Sabino","userId":"07507222221399686296"},"user_tz":0},"id":"8Cly3QJWLRVh","outputId":"2246bceb-f08d-4aed-bbce-5ab94d2940a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["200\n","[[\"time_tag\",\"Kp\",\"a_running\",\"station_count\"],[\"2025-11-28 00:00:00.000\",\"3.67\",\"22\",\"7\"],[\"2025-11-28 03:00:00.000\",\"3.33\",\"18\",\"7\"],[\"2025-11-28 06:00:00.000\",\"4.00\",\"27\",\"7\"],[\"2025-11-28 09:00:00.000\",\"4.00\",\"27\",\"7\"],[\"2025-11-28 12:00:00.000\",\"3.67\",\"22\",\"7\"],[\"2025-11-28 15:00:00.000\",\"4.00\",\"27\",\"7\"],[\"2025-11-28 18:00:00.000\",\"3.67\",\"22\",\"7\"],[\"2025-11-28 21:00:00.000\",\"2.67\",\"12\",\"7\"],[\n"]}],"source":["import requests\n","url = \"https://services.swpc.noaa.gov/products/noaa-planetary-k-index.json\"\n","r = requests.get(url, timeout=5)\n","print(r.status_code)\n","print(r.text[:400])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKg_45f5ahrF"},"outputs":[],"source":["@lru_cache(maxsize=512)\n","def _translate_cached(text: str, target_lang: str) -> str:\n","    if GoogleTranslator is None or target_lang == \"en\":\n","        return text\n","\n","    try:\n","        return GoogleTranslator(source=\"en\", target=target_lang).translate(text)\n","    except Exception as e:\n","        if st.session_state.get(\"show_translate_error_once\", True):\n","            st.session_state[\"show_translate_error_once\"] = False\n","            st.warning(\n","                \"Automatic translation is temporarily unavailable. \"\n","                \"Using English as fallback.\"\n","            )\n","        return text\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOTzM1E+Cs7mpk8PhMSMPDA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}